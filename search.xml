<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>Kafka消费者详解</title>
      <link href="/haze/2020/09/07/environment/kafka/kafkaconsumer/"/>
      <url>/haze/2020/09/07/environment/kafka/kafkaconsumer/</url>
      
        <content type="html"><![CDATA[<h3 id="Kafka-消费者"><a href="#Kafka-消费者" class="headerlink" title="Kafka 消费者"></a>Kafka 消费者</h3><h4 id="一、消费者与消费者组"><a href="#一、消费者与消费者组" class="headerlink" title="一、消费者与消费者组"></a>一、消费者与消费者组</h4><p>   消费者（ Consumer ）负责订阅 Kafka 中的主题（ Topic ），并且从订阅的主题上拉取消息与其他一些消息中间件不同的是：在 Kafka 的消费理念中还有一层消费组（ Consumer Group)的概念，每个消费者都有一个对应的消费组。当消息发布到主题后，只会被投递给订阅它的每个消费组中的一个消费者。</p><p><img src="/haze/2020/09/07/environment/kafka/kafkaconsumer/consumer01.png" alt="多个消费者组"></p><p>   如上图所示，主题存在四个分区（p0/p1/p2/p3），有两个消费者组A和B，A中的四个消费者每人消费了一个分区，而B中的消费者每人消费了2个分区，换而言之，kafka中的一个分区只允许被一个消费者消费。</p><p><img src="/haze/2020/09/07/environment/kafka/kafkaconsumer/consumer02.png" alt="消费者组中只有一个消费者"></p><p>   再如上图中，一个消费者组中只含有一个消费者，则这个消费者将消费所有的分区数据。组中此时新增一个消费者，则此时新增加的消费者会被分配尽可能平均的分区进行消费，如下图所示：</p><p><img src="/haze/2020/09/07/environment/kafka/kafkaconsumer/consumer03.png" alt="消费者组中新增一个消费者"></p><p>   对消费者组依次增加消费者数量，直到超过分区数为止，如下图所示，当消费者数量超过分区数时，会有部分消费者无法消费分区数据，因为一个分区只能背一个消费者消费。</p><p><img src="/haze/2020/09/07/environment/kafka/kafkaconsumer/consumer04.png" alt="消费者组中新增一个消费者"></p><p>   以上分配逻辑都是基于默认的分区分配策略进行分析的，可以通过消费者客户端参数<br>partition.assignment.strategy 来设置消费者与订阅主题之间的分区分配策略。</p><h4 id="二、消费者客户端开发"><a href="#二、消费者客户端开发" class="headerlink" title="二、消费者客户端开发"></a>二、消费者客户端开发</h4><pre><code>public class KafkaConsumerAnalysis {    public static final String brokerList = &quot;localhost:9092&quot;;    public static final String topic = &quot;topic-demo&quot;;    public static final String groupid = &quot;group.demo&quot;;    public static final AtomicBoolean isRunning =new AtomicBoolean(true);    public static Properties initConfig() {        Properties props = new Properties();        props.put(&quot;key.deserializer&quot;,                &quot;org.apache.kafka.common.seriali zation.StringDeserializer&quot;);        props.put(&quot;value.deserializer&quot;,                &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);        props.put(&quot;bootstrap.servers&quot;, brokerList);        props.put(&quot;group.id&quot;, groupid);        props.put(&quot;client.id&quot; ,&quot;consumer.client.id.demo&quot;);        return props;    }    public static void main (String [] args) {        Properties props = initConfig();        KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(props);        consumer.subscribe(Arrays.asList(topic));        try {            while (isRunning.get()) {                ConsumerRecords&lt;String, String&gt; records =                        consumer.poll(Duration.ofMillis(1000));                for (ConsumerRecord&lt;String, String&gt; record : records) {                    System.out.println(&quot;topic = &quot; + record.topic() + &quot;,partition = &quot; + record.partition() + &quot;,offset = &quot; + record.offset());                    System.out.println(&quot;key = &quot; + record.key() + &quot;, value = &quot; + record.value());                }            }        }catch (Exception ex){            ex.printStackTrace();        }finally {            consumer.close();        }    } }</code></pre>]]></content>
      
      
      <categories>
          
          <category> kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
            <tag> consumer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Kafka生产者详解</title>
      <link href="/haze/2020/07/05/environment/kafka/kafkaproducer/"/>
      <url>/haze/2020/07/05/environment/kafka/kafkaproducer/</url>
      
        <content type="html"><![CDATA[<h3 id="Kafka生产者详解"><a href="#Kafka生产者详解" class="headerlink" title="Kafka生产者详解"></a>Kafka生产者详解</h3><h4 id="一、客户端开发"><a href="#一、客户端开发" class="headerlink" title="一、客户端开发"></a>一、客户端开发</h4><h5 id="1、客户端代码示例"><a href="#1、客户端代码示例" class="headerlink" title="1、客户端代码示例"></a>1、客户端代码示例</h5><p>上节对生产者客户端做了基本演示，这节对其进行修改后做具体分析</p><pre><code>import java.util.Properties;import org.apache.kafka.clients.producer.KafkaProducer;import org.apache.kafka.clients.producer.ProducerConfig;import org.apache.kafka.clients.producer.ProducerRecord;import org.apache.kafka.common.serialization.StringSerializer;public class KafkaProducerTest {    public static final String brokerList = &quot;localhost:9092&quot;;    public static final String topic = &quot;topic-demo&quot;;    public static String sendMsg = &quot;this is kafka test message&quot;;    public static Properties initConfig(){        Properties properties = new Properties();        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,                StringSerializer.class.getName());        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,                StringSerializer.class.getName());        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,                brokerList);        properties.put(ProducerConfig.CLIENT_ID_CONFIG,&quot;producer.client.id.demo&quot;);        return properties;    }    public static void main(String[] args) {        Properties properties = initConfig();        // 配置生产者客户端参数并创建kafkaProducer实例        KafkaProducer&lt;String,String&gt; producer = new KafkaProducer&lt;String, String&gt;(properties);        // 构建需要发送的消息        ProducerRecord&lt;String,String&gt; record = new ProducerRecord&lt;&gt;(topic,sendMsg);        try {            // 发送消息            producer.send(record);        }catch (Exception ex){            ex.printStackTrace();        }finally {            // 关闭生产者客户端实例            producer.close();        }    }}</code></pre><h5 id="2、ProducerRecord消息对象"><a href="#2、ProducerRecord消息对象" class="headerlink" title="2、ProducerRecord消息对象"></a>2、ProducerRecord消息对象</h5><pre><code>public class ProducerRecord&lt;K,V&gt;{    private final String topic;        //主题    private final Integer partition;   // 分区号    private final Headers headers;     // 消息头部    private final K key;               // 键    private final V value;             // 值    private final Long timestamp;      // 消息的时间戳    // 省略其他成员方法和构造方法}</code></pre><p>kafkaProducer是线程安全的，可以在多个线程中共享单个的kafkaProducer实例，也可以将kafkaProducer实例进行池化来供其他线程调用。</p><h4 id="二、必要的参数配置"><a href="#二、必要的参数配置" class="headerlink" title="二、必要的参数配置"></a>二、必要的参数配置</h4><p>在创建真正的生产者实例前需要配置相应的参数，如KafkaProducer中有3个参数是必填的</p><h5 id="1、bootstrap-servers"><a href="#1、bootstrap-servers" class="headerlink" title="1、bootstrap.servers"></a>1、bootstrap.servers</h5><p>   指定生产者客户端连接kafka需要的broker地址清单，内容格式为 ip1:port1,ip2:port2，可以设置一个或者多个地址，中间用逗号隔开，默认值为“ ”,并不需要设置所有的地址，能根据一个地址找到集群中的其余地址。但是建议设置多个，当一个地址宕机时，能够切换到其余地址上进行连接。</p><h5 id="2、key-serializer-和-value-serializer"><a href="#2、key-serializer-和-value-serializer" class="headerlink" title="2、key.serializer 和 value.serializer"></a>2、key.serializer 和 value.serializer</h5><p>   boker接收消息必须以字节数组的形式存在。生产者在往broker发送消息前需要将消息中对应的key和value进行相应的序列化操作来转换成字节数组，key.serializer 和 value.serializer两个参数分别指定了序列化的序列化操作器，必须填写全限定名</p><h5 id="3、client-id"><a href="#3、client-id" class="headerlink" title="3、client.id"></a>3、client.id</h5><p>   用来设置KafkaProducer对应的客户端id，默认值为“ ”，若客户端不设置，则KafkaProducer自动生成一个非空字符串，内容形如“producer-1”，“producer-2”，即字符串“producer-”与数字的拼接。</p><h4 id="三、消息的发送"><a href="#三、消息的发送" class="headerlink" title="三、消息的发送"></a>三、消息的发送</h4><p>   创建生产者的实例和构建消息后就可以开始发送消息了，发送消息主要有三种模式：<strong>发后即忘</strong>、<strong>同步</strong>、<strong>异步</strong>。<br>   KafkaProducer的send()方法并非是void类型的，而是Future<RecordMetadata>类型，send()有两个重载方法，分别对应同步和异步</RecordMetadata></p><pre><code># 同步public Future&lt;RecordMetadata&gt; send(ProducerRecord&lt;K,V&gt; record);# 异步public Future&lt;RecordMetadata&gt; send(ProducerRecord&lt;K,V&gt; record,Callback callback);</code></pre><h5 id="1、即忘型"><a href="#1、即忘型" class="headerlink" title="1、即忘型"></a>1、即忘型</h5><p>   前面的代码就即忘型，发送之后不管消息是否到达，大多数情况下这种发送方式没有问题，但发生不可重试异常时会造成消息丢失。这种方式性能最高，可靠性却是最差。</p><h5 id="2、同步"><a href="#2、同步" class="headerlink" title="2、同步"></a>2、同步</h5><p>   要实现同步的消息发送，可以利用返回的Future对象实现，如下：</p><pre><code>try {    // 发送消息    producer.send(record).get();}catch (Exception ex){    ex.printStackTrace();}finally {    // 关闭生产者客户端实例    producer.close();}</code></pre><p>   send()方法本身就是异步的，send()方法返回的Future对象可以使调用方稍后获得发送的结果，在执行send()方法后直接链式调用了get()方法来阻塞等待kafka的响应，直到消息发送成功或者发生异常。如下：</p><pre><code>try {    // 发送消息    Future&lt;RecordMetadata&gt; future = producer.send(record);    RecordMetadata recordMetadata = future.get();    System.out.println(recordMetadata.topic() + &quot;-&quot; + recordMetadata.partition() + &quot;:&quot; + recordMetadata.offset());}catch (Exception ex){    ex.printStackTrace();}finally {    // 关闭生产者客户端实例    producer.close();}</code></pre><p>   这样可以获取一个RecordMetadata对象，RecordMetadata对象中包含了消息的一些元数据信息，比如当前消息的主题、分区号、分区中的偏移量（offset）、时间戳等。</p><p>   KafkaProducer中一般会发生两种类型的异常：可重试异常和不可重试异常。常见的可重试异常有：网络异常、分区leader副本不可用异常（发生在leader副本下线而新leader未被选举出来的时候）。不可重试异常如：RecordTooLargeException（发送消息太大），无法重试，会直接抛出异常。</p><p>   对于可重试异常，如果配置了<strong>retries</strong>参数，只要在规定的重试次数内自行恢复就不会抛出异常，默认为0,配置参考如下：</p><pre><code>properties.put(ProducerConfig.RETRIES_CONFIG,5);</code></pre><h5 id="3、异步"><a href="#3、异步" class="headerlink" title="3、异步"></a>3、异步</h5><p>   异步的发送方式一般是send()方法里指定一个Callback回调函数，kafka在返回响应时调用该函数来实现异步发送消息的确认，异步发送示例如下：</p><pre><code>producer.send(record, new Callback() {                @Override                public void onCompletion(RecordMetadata recordMetadata, Exception e) {                    if (e !== null){                        e.printStackTrace();                    }else {                        System.out.println(recordMetadata.topic() + &quot;-&quot; + recordMetadata.partition() + &quot;:&quot; + recordMetadata.offset());                    }                }});</code></pre><p>   这只是一个简单的调用demo，实际情况中对于异常肯定会进行更加妥善的处理，消息发sing成功时，异常为空而recordMetadata不为空，消息发送异常时，recordMetadata为空而异常不为空。</p><pre><code>producer.send(record1, callback1);producer.send(record2, callback2);</code></pre><p>   对于同一个分区而言，如果record1比record2先发送，那么可以保证callback1比callback2先调用，也就是说回调函数的调用可以保证分区有序。</p><pre><code>try {    int i = 0;    while (i &lt; 100){        ProducerRecord&lt;String,String&gt; recordDemo = new ProducerRecord&lt;&gt;(topic,&quot;test&quot;+i);        producer.send(recordDemo).get();    }}catch (Exception ex){    ex.printStackTrace();}finally {    // 关闭生产者客户端实例    producer.close();}</code></pre><p>  close()方法会阻塞等待之前所有的发送请求完成后再关闭KafakProducer。除此之外KafakProducer还提供了一个带超时时间的close()方法。如下：</p><pre><code>public void close(long timeout, TimeUnit timeUnit);</code></pre><p>   如果调用了带超时时间timeout的close()方法，那么只会在等待timeout时间内来完成尚未处理完成的请求处理，然后强行退出，实际使用中，一般使用无参方法。</p><h4 id="四、序列化"><a href="#四、序列化" class="headerlink" title="四、序列化"></a>四、序列化</h4><h5 id="1、默认序列化器"><a href="#1、默认序列化器" class="headerlink" title="1、默认序列化器"></a>1、默认序列化器</h5><p>   生产者需要使用序列化器吧对象转换为字节数组才能通过网络发送给Kafka。前面的代码中序列化器使用了客户端自带的<strong>StringSerializer</strong>,除了用于String类型的序列化器，还有ByteArray、ByteBuffer、Bytes、Double、Integer、Long这几种类型，他们都实现了<strong>org.apache.kafka.common.serialization.Serializer</strong>接口，此接口有三个方法，分别是：</p><pre><code>public void configure(Map&lt;String,?&gt; config,boolean isKey);public byte[] serialize(String topic,T data);public void close();</code></pre><p> configure() 方法用来配置当前类，在创建KafkaProducer的时候被调用，serialize()方法用来执行序列化操作。close()方法用来执行当前序列化器，一般情况下close()是一个空方法 ，如果实现了这个方法就需要保证这个方法的幂等性，因为这个方法会被KafkaProducer调用多次。</p><h5 id="2、自定义序列化器"><a href="#2、自定义序列化器" class="headerlink" title="2、自定义序列化器"></a>2、自定义序列化器</h5><p>   假设我们要发送的消息是一个Company对象，对象的属性含有name和address，具体如下（这里使用了lombok插件）：</p><pre><code>import lombok.*;@Setter@Getter@NoArgsConstructor@AllArgsConstructor@ToStringpublic class Company {    private String name;    private String address;}</code></pre><p>  再来看一下Company对应的序列化器，CompanySerializer，如下所示：</p><pre><code>public class CompanySerializer implements Serializer&lt;Company&gt; {    @Override    public void configure(Map&lt;String, ?&gt; configs, boolean isKey) {    }    @Override    public byte[] serialize(String s, Company company) {        if (company == null){            return null;        }        byte[] name,address;        try {            if (company.getName() != null){                name = company.getName().getBytes(&quot;UTF-8&quot;);            }else {                name = new byte[0];            }            if (company.getAddress() != null){                address = company.getAddress().getBytes(&quot;UTF-8&quot;);            }else {                address = new byte[0];            }            ByteBuffer buffer = ByteBuffer.allocate(4+4+name.length+address.length);            buffer.putInt(name.length);            buffer.put(name);            buffer.putInt(address.length);            buffer.put(address);            return buffer.array();        }catch (Exception ex){            ex.printStackTrace();        }        return new byte[0];    }    @Override    public byte[] serialize(String topic, Headers headers, Company data) {        return new byte[0];    }    @Override    public void close() {    }}</code></pre><p>上面的这个自定义序列化器很简单，configure()和close()方法都为空。对应的类反序列化器将在<strong>消费者详解</strong>章节讲到，那么如何使用这个自定义的序列化器呢，下面做个简单的演示。</p><pre><code>Properties properties = new Properties();properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,StringSerializer.class.getName());properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,CompanySerializer.class.getName());properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, brokerList);KafkaProducer&lt;String,Company&gt; kafkaProducer = new KafkaProducer&lt;String, Company&gt;(properties);Company company = Company.builder().name(&quot;hiddenkafka&quot;).address(&quot;China&quot;).build();ProducerRecord&lt;String,Company&gt; producerRecord            = new ProducerRecord&lt;String,Company&gt;(topic,company);producer.send(producerRecord).get();</code></pre><h4 id="五、分区器"><a href="#五、分区器" class="headerlink" title="五、分区器"></a>五、分区器</h4><p>   消息通过send()方法发送broker的过程中，有可能需要经过拦截器、序列化器、分区器的一系列操作之后才不能被真正的发往kafka，消息经过序列化之后就需要确认发往的分区，，如果消息ProducerRecord中指定了partition字段，就不需要分区器的作用，因为partition即是指定发往的分区。若没有指定分区则需要依赖分区器，根据key这个字段来计算分区的值。</p><p>   kafka中默认分区器是org.apache.kafka.clients.producer.internals.DefaultPartitioner,它实现了org.apache.kafka.clients.producer.Partitioner接口，这个接口中定义了如下两个方法：</p><pre><code>public int partition(String topic,Object key,byte[] keyBytes,Object value,byte[] valueByte,Cluster cluster);public void close();</code></pre><p>   其中partition()方法用来计算分区号，方法中的参数分别为主题、键、序列化后的键、值、序列化后的值，以及集群的元数据信息。close()方法是空方法。</p><p>   partition()方法定义了主要的分区逻辑，如果key不为null，默认分区器会对key进行哈希（采用MurmurHash2算法，具备高运算性能及低碰撞率），最终根据得到的哈希值来计算分区号，拥有相同key的消息会被写入同一个分区，如果key为null，消息会以轮询的方式发往主题的各个可用分区。</p><p>   <strong>注意：如果key不为null，那么计算得到的分区号可以是所有分区中的任意一个，，如果key为null且有可用分区时，那么计算得到的分区号仅为可用分区中的任意一个，注意两者之间的差别。</strong></p><p>   在不改变主题分区数量的情况下，key与分区之间的映射关系是保持不变的，不过主题中一旦增加分区就无法保证了。除了可以使用默认分区器之外还能通过实现Partitioner接口来自定义分区器。如下:</p><pre><code>public class DemoPartitioner implements Partitioner {    private final AtomicInteger counter = new AtomicInteger(0);    @Override    public int partition(String s, Object o, byte[] bytes, Object o1, byte[] bytes1, Cluster cluster) {        List&lt;PartitionInfo&gt; partitionInfos = cluster.partitionsForTopic(s);        int num = partitionInfos.size();        if (bytes == null){            return  counter.getAndIncrement() % num;        }else {            return Utils.toPositive(Utils.murmur2(bytes)) % num;        }    }    @Override    public void close() {}    @Override    public void configure(Map&lt;String, ?&gt; map) {}}</code></pre><p>   实现自定义的分区器后，需要通过配置参数<strong>partitioner.class</strong> 来显式指定这个分区器，如下：</p><pre><code>properties.put(ProducerConfig.PARTITIONER_CLASS_CONFIG,                DemoPartitioner.class.getName());</code></pre><h4 id="六、生产者拦截器"><a href="#六、生产者拦截器" class="headerlink" title="六、生产者拦截器"></a>六、生产者拦截器</h4><p>   kafka一共有两种拦截器，生产者拦截器和消费者拦截器。生产者拦截器既可以用来在消息发送前做一些准备工作，比如按照某个规则过滤不符合要求的消息、修改消息内容等，也可以用来在发哦送回调逻辑前做一些定制化的需求，比如进行统计等。</p><p>   生产者拦截器主要是自定义实现<strong>org.apache.kafka.clients.producer.ProduerInterceptor</strong>接口，接口中包含三个方法：</p><pre><code>public ProducerRecord&lt;K,V&gt; onSend(ProducerRecord&lt;K,V&gt; record);public void onAcknowledgement(RecordMetadata metadata,Exception exception);public void close();</code></pre><p>   KafkaProducer在将消息序列化和计算分区之前会调用生产者的拦截器onSend()方法，来对消息进行定制化操作。一般不要对ProducerRecord的topic、key和partition等消息做修改，比如修改key会对分区计算机broker端日志压缩产生影响。</p><p>kafkaProducer会在消息被应答之前或者消息发送失败时调用生产者拦截器的onAcknowledgement()方法，优先于用户调用的callback之前调用，这个方法运行在producer的I/O线程中，所以这个方法逻辑越简单越好，否则会影响消息的发送速度。</p><p>   close()方法主要用于在关闭拦截器时执行的一些资源的清理工作。这三个方法中抛出的异常都会被记录到日志中，但不会再向上传递。</p><pre><code>public class ProducerInterceptorPrefix implements ProducerInterceptor&lt;String,String&gt; {    private volatile long sendSuccess = 0;    private volatile long sendFailure = 0;    @Override    public ProducerRecord&lt;String, String&gt; onSend(ProducerRecord&lt;String, String&gt; producerRecord) {        String modifiedValue = &quot;prefix1-&quot;+producerRecord.value();        return new ProducerRecord&lt;&gt;(producerRecord.topic(),                producerRecord.partition(),producerRecord.timestamp(),                producerRecord.key(),modifiedValue,producerRecord.headers());    }    @Override    public void onAcknowledgement(RecordMetadata recordMetadata, Exception e) {        if (e == null){            sendSuccess ++;        }else {            sendFailure ++;        }    }    @Override    public void close() {        double successRatio = (double)sendSuccess/(sendFailure+sendSuccess);        System.out.println(&quot;[Info]发送成功率=&quot;+String.format(&quot;%f&quot;,successRatio*100)+&quot;%&quot;);    }    @Override    public void configure(Map&lt;String, ?&gt; map) { }}</code></pre><p>   实现自定义的<strong>ProducerInterceptorPrefix</strong> 之后，需要在kafkaProducer配置参数 <strong>interceptor.classes</strong> 中指定这个拦截器，此参数默认值为” “，如下：</p><pre><code>properties.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG,                ProducerInterceptorPrefix.class.getName());</code></pre><p>发送10条内容为 <strong>kafka test message</strong> 的信息，会发现消费了的信息都变成了 <strong>prefix1-kafka test message</strong>,kafka 中不仅可以指定一个拦截器，还可以指定多个拦截器行成一个拦截链，拦截链的执行顺序会按照参数（<strong>interceptor.classes</strong>）的配置顺序来执行,多个拦截器用逗号隔开。若存在另一个名为 <strong>ProducerInterceptorPrefixPlus</strong> 的拦截器，onSend()方法【配置如下：</p><pre><code> @Override    public ProducerRecord&lt;String, String&gt; onSend(ProducerRecord&lt;String, String&gt; producerRecord) {        String modifiedValue = &quot;prefix2-&quot;+producerRecord.value();        return new ProducerRecord&lt;&gt;(producerRecord.topic(),                producerRecord.partition(),producerRecord.timestamp(),                producerRecord.key(),modifiedValue,producerRecord.headers());    }</code></pre><p>   配置生产者拦截器 拦截链：</p><pre><code>properties.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG,                ProducerInterceptorPrefix.class.getName() +&quot;,&quot;+                ProducerInterceptorPrefixPlus.class.getName());</code></pre><p>   那么最终发送的消息为：<strong>prefix2-prefix1-kafka test message</strong><br>   <strong>注意：若拦截器间存在依赖关系，即当前拦截器依赖于上一个拦截器的执行结果，则会存在问题，比如上一个拦截器出现异常，导致执行失败的情况。</strong></p><h4 id="七、生产者整体架构简述"><a href="#七、生产者整体架构简述" class="headerlink" title="七、生产者整体架构简述"></a>七、生产者整体架构简述</h4><p><img src="/haze/2020/07/05/environment/kafka/kafkaproducer/producer01.png" alt="生产者客户端整体架构"></p><p>   整个生产者客户端由2个线程协调运行，分别为主线程和sender线程（发送线程）。在主线程中由 afkaProducer 创建消息，然后通过可能的拦截器、序列化器和分区器的作用之后缓存到消息累加器（ RecordAccumulator ，也称为消息收集器〉中。 Sender 线程负责从RecordAccumulator 获取消息并将其发送到 Kafka</p><p>   RecrdAccumulator主要用来缓存消息以便 Sender 线程可以批量发送，进 减少网络传输的资源消耗以提升性能 RecordAccumulator 缓存的大 小可以通过生产者客户端参数buffer memory 配置，默认值为 33554432B ，即 32MB 如果生产者发送消息的速度超过发送到服务器的速度 ，则会导致生产者空间不足，这个时候 KafkaProducer的 send（） 方法调用要么被阻塞，要么抛出异常，这个取决于参数 max block ms 的配置，此参数的默认值为 60000,即60秒。</p><p>   <strong>注意ProducerBatch不是ProducerRecord，ProducerBatch中包含一至多个ProducerRecord</strong></p><h4 id="八、重要的生产者参数"><a href="#八、重要的生产者参数" class="headerlink" title="八、重要的生产者参数"></a>八、重要的生产者参数</h4><h5 id="1、acks"><a href="#1、acks" class="headerlink" title="1、acks"></a>1、acks</h5><p>   这个参数用来指定分区中必须要有多少个副本收到这条消息，之后生产者才会认为这条消息是成功写入的。 acks 是生产者客户端中一个非常重要的参数 ，它涉及消息的可靠性和吞吐量之间的权衡。acks有三种设定值（均为字符串格式）</p><h6 id="acks-1"><a href="#acks-1" class="headerlink" title="acks = 1"></a>acks = 1</h6><p>   默认值即为1，生产者消息发送成功后，只要分区的 <strong>leader副本</strong> 消息写入成功，就会给kafaka生产者返回一个成功响应。如果消息发送过程中leader副本挂了或者处于重新选举leader的过程中，则会返回发送错误的响应结果。若在其余副本同步leader副本之前leader崩溃，则还是会存在丢数的情况。这种设置是均衡吞吐量和可靠性的折中方案。</p><h6 id="acks-0"><a href="#acks-0" class="headerlink" title="acks = 0"></a>acks = 0</h6><p>   生产者发送kafka之后无需等待kafka回复，若消息发送过程中出现异常导致消息发送失败也无从得知，但在其它配置相同的情况 <strong>acks = 0</strong> 可以达到最大的吞吐量。</p><h6 id="acks-1-acks-all"><a href="#acks-1-acks-all" class="headerlink" title="acks = -1 / acks = all"></a>acks = -1 / acks = all</h6><p>   生产者在发送消息之后，需要等待所有的ISR副本都成功写入消息后才会返回成功给客户端。在其它环境配置相同的情况下，该配置能达到最高可靠性。但这不是绝对的，当一个分区只有一个副本时，此设置和asks=1的情况是一样的。要获取更高的消息可靠性需要配合 <strong>min.insync.replicas</strong> 等参数的联动。</p><p><strong>注意 acks 参数配置的值是一个字符串类型，而不是整数类型</strong>，如下：</p><pre><code>properties put(&quot;acks&quot;，&quot;1&quot;）；# 或者properties.put(ProducerConfig.ACKS_CONFIG,&quot;0&quot;）；# 若为properties put(&quot;acks&quot;，1）；则会报错，因为值的类型应该为String。</code></pre><p><img src="/haze/2020/07/05/environment/kafka/kafkaproducer/producer_error01.png" alt="acks参数设置错误"></p><h5 id="2、max-request-size"><a href="#2、max-request-size" class="headerlink" title="2、max.request.size"></a>2、max.request.size</h5><p>   这个参数用来限制生产者客户端能发送的消息的最大值，默认值为 1048576B ，即 1MB.不建议读者盲目地增大这个参数的配置值,因为这个参数还涉及一些其它参数的联动。比如 broker 端的message.max bytes 参数。比如将 broker 端的 message max.bytes 参数配置为 10 ，而max.request size参数配置为20, 那么当我们 发送一条大小为 15B 的消息时，生产者客户端就会报出如下的异常</p><p><img src="/haze/2020/07/05/environment/kafka/kafkaproducer/producer_error02.png" alt="acks参数设置错误"></p><h5 id="3、retries-retry-backoff-ms"><a href="#3、retries-retry-backoff-ms" class="headerlink" title="3、retries retry.backoff.ms"></a>3、retries retry.backoff.ms</h5><p>   retries 参数用来配置生产者重试的次数，默认值为0，即在发生异常的时候不进行任何重试动作.<br>   重试还和另一个参数 retry.backoff.ms 有关，这个参数的默认值为 100 它用来设定两次重试之间的时间间隔，避免无效的频繁重试。<br>   Kafka 可以保证同一个分区中的消息是有序的。如果生产者按照一定的顺序发送消息，那么这些消息也会顺序地写入分区，进而消费者也可以按照同样的顺序消费它们.</p><h5 id="4、compression-type"><a href="#4、compression-type" class="headerlink" title="4、compression.type"></a>4、compression.type</h5><p>   这个参数用来指定消息的压缩方式，默认值为“none ”，即默认情况下，消息不会被压缩。该参数还可以配置为gzip、snappy 和z4 对消息进行压缩可以极大地减少网络传输量、降低网络I/O ，从而提高整体的性能 。</p><h5 id="5、connections-max-idle-ms"><a href="#5、connections-max-idle-ms" class="headerlink" title="5、connections.max.idle. ms"></a>5、connections.max.idle. ms</h5><p>   这个参数用来指定在多久之后关闭限制的连接，默认值是 540000（ ms） ，即9分钟。</p><h5 id="6、-linger-ms"><a href="#6、-linger-ms" class="headerlink" title="6、 linger.ms"></a>6、 linger.ms</h5><p>   这个参数用来指定生产者发送 ProducerBatch 之前等待更多消息（ ProducerRecord ）加入Producer Batch 时间，默认值为0。</p><h5 id="7、-receive-buffe-bytes"><a href="#7、-receive-buffe-bytes" class="headerlink" title="7、 receive.buffe.bytes"></a>7、 receive.buffe.bytes</h5><p>   这个参数用来设置 Socket 接收消息缓冲区（ SO_RECBUF ）的大小，默认值为 32768(B))，即32KB。如果设置为 -1 ，则使用操作系统的默认值。如果 Producer与Kafka 处于不同的机房<br>则可以适地调大这个参数值</p><h5 id="8、send-buffer-bytes"><a href="#8、send-buffer-bytes" class="headerlink" title="8、send.buffer.bytes"></a>8、send.buffer.bytes</h5><p>   这个参数用来设置 Socket 发送消息缓冲区（CSO_SNDBUF）的大 ，默认值 131072（B）,即128KB 。与 receive.buffer.bytes 参数一样 如果设置为 -1，则使用操作系统的默认值。</p><h5 id="9、request-timeout-ms"><a href="#9、request-timeout-ms" class="headerlink" title="9、request.timeout.ms"></a>9、request.timeout.ms</h5><p>   这个参数用来配置 Producer 等待请求响应的 长时间，默认值为 30000 （ms ）。请求超时之后可以选择进行重试。注意这个参数需要比broker 端参数 replica.lag.time.max.ms值要大，这样可以减少因客户端重试而引起的消息重复的概率。</p>]]></content>
      
      
      <categories>
          
          <category> kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
            <tag> producer </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>java &amp; redis</title>
      <link href="/haze/2020/07/05/environment/redis/redis-cao-zuo/"/>
      <url>/haze/2020/07/05/environment/redis/redis-cao-zuo/</url>
      
        <content type="html"><![CDATA[<h2 id="Redis-常见操作"><a href="#Redis-常见操作" class="headerlink" title="Redis 常见操作"></a>Redis 常见操作</h2><h3 id="一、运维常见命令"><a href="#一、运维常见命令" class="headerlink" title="一、运维常见命令"></a>一、运维常见命令</h3><p><strong>1、启动redis</strong></p><pre><code># 进入redis根目录nohup src/redis-server redis.conf &gt;start.log 2&gt;&amp;1 &amp;</code></pre><p><strong>2、启动redis-sentinel 哨兵</strong></p><pre><code># 进入redis根目录nohup src/redis-sentinel sentinel.conf &gt;start.log 2&gt;&amp;1 &amp;</code></pre><p>*<em>3、停止redis  *</em></p><pre><code>redis-cli shutdown</code></pre><p><strong>4、选择数据库</strong></p><pre><code>//默认连接的数据库所有是0,默认数据库数是16个。返回1表示成功，0失败select db-index</code></pre><p><strong>5、清空数据库</strong></p><pre><code>flushdb    //删除当前选择数据库中的所有 key。生产上已经禁止。flushall   //删除所有的数据库。生产上已经禁止。</code></pre><p><strong>6、模拟宕机</strong></p><pre><code>redis-cli debug segfault</code></pre><p><strong>7、模拟hang</strong></p><pre><code>redis-cli -p 6379 DEBUG sleep 30</code></pre><p><strong>8、重命名命令</strong></p><pre><code>rename-command// 例如：rename-command FLUSHALL &quot;&quot;。必须重启。</code></pre><p><strong>9、设置密码</strong></p><pre><code>config set requirepass [passw0rd]</code></pre><p><strong>10、验证密码</strong></p><pre><code>auth passw0rd</code></pre><p><strong>11、查看日志</strong></p><pre><code>日志位置在/redis/log下，redis.log为redis主日志，sentinel.log为sentinel哨兵日志。</code></pre><h3 id="二、开发常见命令"><a href="#二、开发常见命令" class="headerlink" title="二、开发常见命令"></a>二、开发常见命令</h3><p>自注：key值为队列名</p><p><strong>1、在名称为key的队列尾添加一个值为value的元素</strong></p><pre><code>rpush(key, value)</code></pre><p><strong>2、在名称为key的队列头添加一个值为value的 元素</strong></p><pre><code>lpush(key, value)</code></pre><p><strong>3、返回名称为key的队列的长度</strong></p><pre><code>llen(key)</code></pre><p><strong>4、返回名称为key的队列中start至end之间的元素</strong></p><pre><code>lrange(key, start, end)</code></pre><p><strong>5、截取名称为key的队列</strong></p><pre><code>ltrim(key, start, end)</code></pre><p><strong>6、返回名称为key的队列中index位置的元素</strong></p><pre><code>lindex(key, index)</code></pre><p><strong>7、给名称为key的队列中index位置的元素赋值</strong></p><pre><code>lset(key, index, value)</code></pre><p><strong>8、删除count个key的队列中值为value的元素</strong></p><pre><code>lrem(key, count, value)</code></pre><p><strong>9、返回并删除名称为key的队列中的首元素</strong></p><pre><code>lpop(key)</code></pre><p><strong>10、返回并删除名称为key的队列中的尾元素</strong></p><pre><code>rpop(key)</code></pre><p><strong>11、lpop命令的block版本</strong></p><pre><code>blpop(key1, key2,… key N, timeout)</code></pre><p><strong>12、rpop的block版本</strong></p><pre><code>brpop(key1, key2,… key N, timeout)</code></pre><p><strong>13、返回并删除名称为srckey的队列的尾元素，并将该元素添加到名称为dstkey的list的头部</strong></p><pre><code>rpoplpush(srckey, dstkey)</code></pre><p><strong>14、删除某个队列</strong></p><pre><code>del key</code></pre><p><strong>15、清空redis</strong></p><pre><code>flushdb</code></pre><h3 id="三、java-连接redis"><a href="#三、java-连接redis" class="headerlink" title="三、java 连接redis"></a>三、java 连接redis</h3><p><strong>1、引入redis的依赖：</strong></p><pre><code>&lt;dependency&gt;      &lt;groupId&gt;redis.clients&lt;/groupId&gt;      &lt;artifactId&gt;jedis&lt;/artifactId&gt;      &lt;version&gt;2.5.0&lt;/version&gt;&lt;/dependency&gt;</code></pre><p><strong>2、连接池</strong></p><pre><code>// 用hash方式保存至redispublic boolean saveToRedis(String key,String event,String value){        try {            Jedis jedis = getJedisPool().getResource();            jedis.hset(key,event,value);        }catch (Exception ex){            DpLogger.GETDATALOG.error(&quot;redis存储异常..&quot;,ex);        }        return true;    }// redis哨兵连接池，redis是类似的private JedisSentinelPool getJedisPool(){        if (jedisPool == null){            lock1.lock();            try {                JedisPoolConfig jedisPoolConfig = new JedisPoolConfig();                jedisPoolConfig.setMaxIdle(30);                // 哨兵连接127.0.0.1:26379,127.0.0.1:26378,127.0.0.1:26377                Set&lt;String&gt; sentinelSet = redisConfiguration.getSentinelHost().stream().collect(Collectors.toSet());                // redisConfiguration.getSentinelService()为服务名                JedisSentinelPool pool = new JedisSentinelPool(redisConfiguration.getSentinelService(),                        sentinelSet, jedisPoolConfig, redisConfiguration.getSentinelPwd());                return pool;            }catch (Exception ex){                DpLogger.GETDATALOG.error(&quot;创建redis连接失败..&quot;,ex);            }finally {                lock1.unlock();            }        }        return jedisPool;    }</code></pre>]]></content>
      
      
      <categories>
          
          <category> command </category>
          
      </categories>
      
      
        <tags>
            
            <tag> redis </tag>
            
            <tag> java </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>初识KAFKA</title>
      <link href="/haze/2020/07/05/environment/kafka/chu-shi-kafka/"/>
      <url>/haze/2020/07/05/environment/kafka/chu-shi-kafka/</url>
      
        <content type="html"><![CDATA[<h3 id="初识KAFKA"><a href="#初识KAFKA" class="headerlink" title="初识KAFKA"></a>初识KAFKA</h3><h4 id="一、-kafka基本概念介绍"><a href="#一、-kafka基本概念介绍" class="headerlink" title="一、 kafka基本概念介绍"></a>一、 kafka基本概念介绍</h4><h5 id="1、kafka扮演的角色"><a href="#1、kafka扮演的角色" class="headerlink" title="1、kafka扮演的角色"></a>1、kafka扮演的角色</h5><p>  <strong>消息系统</strong>：系统解耦、冗余存储、流量削峰、缓冲、异步通信、扩展性、可恢复性等<br>  <strong>存储系统</strong>：将数据消息持久化保存到磁盘<br>  <strong>流式处理平台</strong>：提供完整的流式处理类库，比如窗口、连接、交换和聚合等操作。</p><h5 id="2、kafka的专业术语"><a href="#2、kafka的专业术语" class="headerlink" title="2、kafka的专业术语"></a>2、kafka的专业术语</h5><p> <strong>Producer</strong>：生产者，消息发送方，负责将消息发送到kafka队列中</p><p> <strong>Consumer</strong>：消费者，消息接收方，负责接收kafka队列中的数据并进行相应的业务逻辑处理</p><p> <strong>Broker</strong>：服务代理节点，一般情况下一个broker可以看做是一个kafka服务器</p><h5 id="3、主题（topic）、分区（Partition）及副本-Replica"><a href="#3、主题（topic）、分区（Partition）及副本-Replica" class="headerlink" title="3、主题（topic）、分区（Partition）及副本(Replica)"></a>3、主题（topic）、分区（Partition）及副本(Replica)</h5><p><strong>(1)、</strong> 主题是一个逻辑上的概念，分为多个分区，一个分区只属于单个主题。同一主题下的不同分区消息是不同的。一个分区分为多个副本（大于等于1个）</p><p><strong>(2)、</strong> 一条消息被发送到broker之前，会根据分区规则选择存储到哪个具体的分区。如果分区设置合理，消息会被均匀的分配到不同的分区中。kafka为分区引入了副本机制，增加副本数量可以提升容灾能力。同一分区的副本存储的相同消息，但是同一时刻副本内的消息不一定都是一样的（follwer副本的消息更新一般会稍微滞后于leader），副本间是一主多从关系，leader负责读写请求，follwer只负责与leader的消息进行同步。</p><p><strong>(3)、</strong> 分区中所有副本统称为<strong>AR</strong>。所有与leader副本保持一定程度同步的副本（包括leader）组成<strong>ISR</strong>。与leader信息同步程度滞后太多的副本称为<strong>OSR</strong>。ISR和OSR是AR的一个子集，AR = OSR + ISR。当副本滞后leader太多，该副本会被leader从ISR中剔除。</p><p>*<em>(4)、HW *</em> 标识了一个特别的偏移量，消费者只能拉取到这个值之前的消息（比如消费者能消费到的数据是0到5，那么HW的值就为6），HW的值取决于follwer副本与leader副本的同步情况，HW的值为同步的最小offset加1（若leader的值为15，follwer1位12，follwer2为7，则HW的值为8）。若分区队列中消息数量为0到8，则LEO=9，他标识当前日志文件中下一条待写入消息的offset。分区ISR集合中的每个副本都会维护自身的LEO。</p><h4 id="二、-kafka的安装与配置"><a href="#二、-kafka的安装与配置" class="headerlink" title="二、 kafka的安装与配置"></a>二、 kafka的安装与配置</h4><p>详情见另外文档（地址待贴出）</p><h4 id="三、kafka脚本生产与消费"><a href="#三、kafka脚本生产与消费" class="headerlink" title="三、kafka脚本生产与消费"></a>三、kafka脚本生产与消费</h4><p>#####1、创建主题</p><pre><code># 进入kafka的根目录下，使用bin目录下的kafka-topics.sh脚本创建主题bin/kafka-topics.sh --zookeeper localhost:2181/kafka --create --topic topic-demo --replication-factor 3 --partitions 4--zookeeper           指定了kafka所连接的ZK服务地址--topic               指定了要创建的主题名称--replication-factor  指定了副本因子--create              创建主题的动作命令</code></pre><p>#####2、查看主题信息</p><pre><code># 通过 --describe展示主题的具体信息bin/kafka-topics.sh --zookeeper localhost:2181/kafka --describe --topic topic-demo</code></pre><h4 id="3、订阅主题"><a href="#3、订阅主题" class="headerlink" title="3、订阅主题"></a>3、订阅主题</h4><p>  创建主题后通过kafka提供的两个脚本来检查是否可以正常地发送和消费数据</p><pre><code># 使用kafka-console-consumer.sh来订阅主题bin/kafka-console-consumer.sh --bootstrap-server localhost:9200 --topic topic-demo--bootstrap-server    指定了连接的kafka集群地址--topic               指定了消费者订阅的主题</code></pre><p>目前该主题暂无信息写入，所以脚本无法消费数据，再打开另一个终端，在kafka根目录下执行消息发送脚本，发送一条Hello Kafka!的信息</p><pre><code># 使用kafka-console-producer.shbin/kafka-console-producer.sh --broker-list localhost:9092 --topic topic-demo&gt;Hello kafka!&gt;--broker-list      指定了连接kafka集群的地址--topic            指定了发送消息时的主题第二行&gt;后面的信息为发送至kafka主题中的信息</code></pre><p>回到消费kafka的窗口，可以看到刚刚被发送至kafka的信息被获取到</p><h4 id="四、java客户端kafka的发送与消费"><a href="#四、java客户端kafka的发送与消费" class="headerlink" title="四、java客户端kafka的发送与消费"></a>四、java客户端kafka的发送与消费</h4><h5 id="1、kafka的java客户端需要的maven依赖如下"><a href="#1、kafka的java客户端需要的maven依赖如下" class="headerlink" title="1、kafka的java客户端需要的maven依赖如下"></a>1、kafka的java客户端需要的maven依赖如下</h5><pre><code>&lt;dependency&gt;   &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt;   &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt;   &lt;version&gt;2.5.0&lt;/version&gt;&lt;/dependency&gt;</code></pre><h5 id="2、生产者客户端代码"><a href="#2、生产者客户端代码" class="headerlink" title="2、生产者客户端代码"></a>2、生产者客户端代码</h5><pre><code>import org.apache.kafka.clients.producer.KafkaProducer;import org.apache.kafka.clients.producer.ProducerConfig;import org.apache.kafka.clients.producer.ProducerRecord;import org.apache.kafka.common.serialization.StringSerializer;public class ProducerFastStart{    public static final String brokerList = &quot;localhost:9092&quot;;    public static final String topic = &quot;topic-demo&quot;;    public static String sendMsg = &quot;this is kafka test message&quot;;    public static void main(String[] args) {        Properties properties = new Properties();        properties.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG,                StringSerializer.class.getName());        properties.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG,                StringSerializer.class.getName());        properties.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,                brokerList);        KafkaProducer&lt;String,String&gt; producer                = new KafkaProducer&lt;String, String&gt;(properties);        ProducerRecord&lt;String,String&gt; record                = new ProducerRecord&lt;&gt;(topic,sendMsg);        try {            producer.send(record);        }catch (Exception ex){            ex.printStackTrace();        }finally {            producer.close();        }    }}</code></pre><h5 id="3、消费者客户端代码"><a href="#3、消费者客户端代码" class="headerlink" title="3、消费者客户端代码"></a>3、消费者客户端代码</h5><pre><code>import org.apache.kafka.clients.consumer.ConsumerConfig;import org.apache.kafka.clients.consumer.ConsumerRecord;import org.apache.kafka.clients.consumer.ConsumerRecords;import org.apache.kafka.clients.consumer.KafkaConsumer;import org.apache.kafka.common.serialization.StringDeserializer;import java.time.Duration;import java.util.Collections;import java.util.Properties;public class KafkaConsumerTest {    public static final String brokerList = &quot;localhost:9092&quot;;    public static final String topic = &quot;topic-demo&quot;;    public static final String groupId = &quot;group.demo&quot;;    public static void main(String[] args) {        Properties properties = new Properties();        properties.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG,                StringDeserializer.class.getName());        properties.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG,                StringDeserializer.class.getName());        properties.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG,brokerList);        properties.put(ConsumerConfig.GROUP_ID_CONFIG,groupId);        // 创建一个kafka消费者客户端实例        KafkaConsumer&lt;String,String&gt; consumer = new KafkaConsumer&lt;String, String&gt;(properties);        // 订阅主题        consumer.subscribe(Collections.singletonList(topic));        while (true){            ConsumerRecords&lt;String,String&gt; records = consumer.poll(Duration.ofMillis(1000));            for (ConsumerRecord&lt;String,String&gt; record:records){                System.out.println(record.value());            }        }    }}</code></pre>]]></content>
      
      
      <categories>
          
          <category> kafka </category>
          
      </categories>
      
      
        <tags>
            
            <tag> kafka </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>docker &amp; redis</title>
      <link href="/haze/2020/07/04/environment/redis/docker-redis/"/>
      <url>/haze/2020/07/04/environment/redis/docker-redis/</url>
      
        <content type="html"><![CDATA[<h2 id="docker搭建redis主从及哨兵"><a href="#docker搭建redis主从及哨兵" class="headerlink" title="docker搭建redis主从及哨兵"></a>docker搭建redis主从及哨兵</h2><h3 id="1、前提准备"><a href="#1、前提准备" class="headerlink" title="1、前提准备"></a>1、前提准备</h3><p>docker环境（这里我只使用了一台docker服务器，通过端口区别实现集群）</p><h3 id="2、创建外部挂载目录"><a href="#2、创建外部挂载目录" class="headerlink" title="2、创建外部挂载目录"></a>2、创建外部挂载目录</h3><p>创建目录如下，每个目录下再创建data和conf目录用于外部挂载：<br><img src="/haze/2020/07/04/environment/redis/docker-redis/docker-redis01.png" alt="挂载目录"><br></p><h3 id="3、下载redis配置和哨兵配置"><a href="#3、下载redis配置和哨兵配置" class="headerlink" title="3、下载redis配置和哨兵配置"></a>3、下载redis配置和哨兵配置</h3><pre><code>wget http://download.redis.io/redis-stable/redis.confwget http://download.redis.io/redis-stable/sentinel.conf</code></pre><p>文件下载后拷贝改名，分别放至对应目录下</p><p>redis:（命名分别为：redis_6379.conf/redis_6371.conf/redis_6372.conf）<br>sentinel:（命名分别为：sentinel_1.conf/sentinel_2.conf/sentinel_3.conf）</p><h3 id="4、修改redis配置"><a href="#4、修改redis配置" class="headerlink" title="4、修改redis配置"></a>4、修改redis配置</h3><pre><code># 注释掉使得Redis服务器可以跨网络访问# bind 0.0.0.0# 设置密码requirepass &quot;123456&quot;# 指定主服务器，注意：有关slaveof的配置只是配置从服务器，主服务器不需要配置slaveof 192.168.11.128 6379# 主服务器密码，注意：有关slaveof的配置只是配置从服务器，主服务器不需要配置masterauth 123456# 选择性配置，若配置需确保文件目录存在logfile &quot;&quot;</code></pre><p><strong>配置文件需更改对应端口</strong></p><h3 id="5、启动一台redis"><a href="#5、启动一台redis" class="headerlink" title="5、启动一台redis"></a>5、启动一台redis</h3><pre><code>docker run -p 6372:6372--name redis-6372-v /opt/redis/redis03/conf/redis_6372.conf:/etc/redis/redis_6372.conf-v /opt/redis/redis03/data:/data-d redis redis-server /etc/redis/redis_6372.conf--appendonly yes    # 开启持久化</code></pre><p>启动之后使用命令查看</p><pre><code>docker ps</code></pre><p>未查找到运行中的redis容器，使用命令查看redis容器启动日志</p><pre><code>docker logs ID|less</code></pre><p>发现是logfile日志目录不存在，程序没有自动创建，这里我直接删除这个配置再启动</p><pre><code># 得到容器IDdocker ps -a# 移除容器docker rm ID#启动redis</code></pre><p>使用redis-manager工具连接试试，发现可以连接。再启动其余几台redis，同样进行验证</p><h3 id="6、更改redis哨兵配置"><a href="#6、更改redis哨兵配置" class="headerlink" title="6、更改redis哨兵配置"></a>6、更改redis哨兵配置</h3><pre><code># 禁止保护模式protected-mode no# 配置监听的主服务器，这里sentinel monitor代表监控，mymaster代表服务器的名称，可以自定义，192.168.11.128代表监控的主服务器，6379代表端口，2代表只有两个或两个以上的哨兵认为主服务器不可用的时候，才会进行failover操作。sentinel monitor mymaster 192.168.11.128 6379 2# sentinel author-pass定义服务的密码，mymaster是服务名称，123456是Redis服务器密码# sentinel auth-pass &lt;master-name&gt; &lt;password&gt;sentinel auth-pass mymaster 123456</code></pre><p><strong>这里需要注意的是，如果不使用默认的服务名mymaster，如更改为了sentinel-server，则需要将配置中所有涉及服务名的地方进行更改，如超时时间，且端口应配置为不一样</strong></p><h3 id="7、启动哨兵"><a href="#7、启动哨兵" class="headerlink" title="7、启动哨兵"></a>7、启动哨兵</h3><pre><code>docker run -p 26379:26379--name sentinel-26379-v /opt/redis/sentinel01/conf/sentinel_1.conf:/etc/redis/sentinel.conf-v /opt/redis/sentinel01/data:/data-d redis redis-sentinel /etc/redis/sentinel.conf</code></pre><p>启动后执行命令查看是否启动成功</p><pre><code>docker ps</code></pre><p>最后情况应该如下：<br><img src="/haze/2020/07/04/environment/redis/docker-redis/docker-redis02.png" alt="运行情况"><br></p>]]></content>
      
      
      <categories>
          
          <category> encironment </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>docker &amp; tomcat</title>
      <link href="/haze/2020/07/04/environment/redis/docker-tomcat7/"/>
      <url>/haze/2020/07/04/environment/redis/docker-tomcat7/</url>
      
        <content type="html"><![CDATA[<h2 id="Docker-tomcat7"><a href="#Docker-tomcat7" class="headerlink" title="Docker+tomcat7"></a>Docker+tomcat7</h2><h3 id="一、DockerFile"><a href="#一、DockerFile" class="headerlink" title="一、DockerFile"></a>一、DockerFile</h3><pre><code>############################################# version : birdben/tomcat7:v1# desc : 当前版本安装的tomcat7############################################# 设置继承自我们创建的 jdk7 镜像FROM birdben/jdk7:v1# 下面是一些创建者的基本信息MAINTAINER birdben (191654006@163.com)# 设置环境变量，所有操作都是非交互式的ENV DEBIAN_FRONTEND noninteractive# 添加 supervisord 的配置文件，并复制配置文件到对应目录下面。（supervisord.conf文件和Dockerfile文件在同一路径）COPY supervisord.conf /etc/supervisor/conf.d/supervisord.conf# 设置 tomcat 的环境变量，若读者有其他的环境变量需要设置，也可以在这里添加。ENV CATALINA_HOME /software/tomcat7# 复制 apache-tomcat-7.0.55 文件到镜像中（apache-tomcat-7.0.55 文件夹要和Dockerfile文件在同一路径）ADD apache-tomcat-7.0.55 /software/tomcat7# 容器需要开放Tomcat 8080端口EXPOSE 8080# 执行supervisord来同时执行多个命令，使用 supervisord 的可执行路径启动服务。CMD [&quot;/usr/bin/supervisord&quot;]</code></pre><h3 id="二、run-sh"><a href="#二、run-sh" class="headerlink" title="二、run.sh"></a>二、run.sh</h3><pre><code>docker run -p 9999:22 -p 8080:8080 -t -i birdben/tomcat7:v1</code></pre><h3 id="三、supervisord-conf"><a href="#三、supervisord-conf" class="headerlink" title="三、supervisord.conf"></a>三、supervisord.conf</h3><pre><code># 配置文件包含目录和进程# 第一段 supervsord 配置软件本身，使用 nodaemon 参数来运行。# 第二段包含要控制的 2 个服务。每一段包含一个服务的目录和启动这个服务的命令。[supervisord]nodaemon=true[program:sshd]command=/usr/sbin/sshd -D[program:tomcat]command=/bin/bash -c &quot;exec ${CATALINA_HOME}/bin/catalina.sh run&quot;</code></pre>]]></content>
      
      
      <categories>
          
          <category> encironment </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Docker </tag>
            
            <tag> tomcat </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linix &amp; redis</title>
      <link href="/haze/2020/07/03/environment/redis/redis-zhu-cong-ji-shao-bing/"/>
      <url>/haze/2020/07/03/environment/redis/redis-zhu-cong-ji-shao-bing/</url>
      
        <content type="html"><![CDATA[<h2 id="redis主从及哨兵"><a href="#redis主从及哨兵" class="headerlink" title="redis主从及哨兵"></a>redis主从及哨兵</h2><p>比较简陋的搭建一个主从及哨兵</p><h3 id="1、创建目录-opt-app-redis-如下："><a href="#1、创建目录-opt-app-redis-如下：" class="headerlink" title="1、创建目录/opt/app/redis,如下："></a>1、创建目录/opt/app/redis,如下：</h3><pre><code>mkdir /opt/app/redis</code></pre><h3 id="2、下载redis安装包至目录下，复制3份，各自重命名，并解压："><a href="#2、下载redis安装包至目录下，复制3份，各自重命名，并解压：" class="headerlink" title="2、下载redis安装包至目录下，复制3份，各自重命名，并解压："></a>2、下载redis安装包至目录下，复制3份，各自重命名，并解压：</h3><pre><code>tar xvfz m.tar.gz</code></pre><h3 id="3、自定义配置redis-conf。"><a href="#3、自定义配置redis-conf。" class="headerlink" title="3、自定义配置redis.conf。"></a>3、自定义配置redis.conf。</h3><pre><code># 使得Redis服务器可以跨网络访问，也可以注释掉，否则可能无法访问端口bind 0.0.0.0# 设置密码requirepass &quot;123456&quot;# 指定主服务器，注意：有关slaveof的配置只是配置从服务器，主服务器不需要配置slaveof 192.168.11.128 6379# 主服务器密码，注意：有关slaveof的配置只是配置从服务器，主服务器不需要配置masterauth 123456</code></pre><p><strong>注意：若在同一台虚拟机上搭建，需要将端口号修改为不同的</strong></p><h3 id="4、启动redis"><a href="#4、启动redis" class="headerlink" title="4、启动redis"></a>4、启动redis</h3><pre><code>nohup /src/redis-server redis.conf &gt;/dev/null 2&gt;&amp;1 &amp;# 查看启动情况ps aux|grep redis</code></pre><p>这里可能找不到redis-server,原因是redis解压后没有构建</p><pre><code># 进入redis的src目录进行构建make install</code></pre><p>这里由于前置环境的原因，可能会报缺少gcc，安装即可</p><pre><code> yum -y install gcc-c++</code></pre><p>依次启动redis后，往主redis放数据，从redis会同步数据。</p><h3 id="5、修改哨兵配置"><a href="#5、修改哨兵配置" class="headerlink" title="5、修改哨兵配置"></a>5、修改哨兵配置</h3><pre><code># 禁止保护模式protected-mode no# 配置监听的主服务器，这里sentinel monitor代表监控，mymaster代表服务器的名称，可以自定义，192.168.11.128代表监控的主服务器，6379代表端口，2代表只有两个或两个以上的哨兵认为主服务器不可用的时候，才会进行failover操作。sentinel monitor mymaster 192.168.11.128 6379 2# sentinel author-pass定义服务的密码，mymaster是服务名称，123456是Redis服务器密码# sentinel auth-pass &lt;master-name&gt; &lt;password&gt;sentinel auth-pass mymaster 123456</code></pre><p>若不用默认的mymaster服务名，修改服务名时，需将配置中的所有mymaster替换为新服务名（如：sentinel-server）</p><h3 id="6、启动哨兵"><a href="#6、启动哨兵" class="headerlink" title="6、启动哨兵"></a>6、启动哨兵</h3><pre><code>nohup /src/sentinel-server sentinel.conf &gt;/dev/null 2&gt;&amp;1 &amp;</code></pre><p>代码中连接哨兵即可使用redis主从，且当主redis宕机，哨兵会自动切换至从redis</p>]]></content>
      
      
      <categories>
          
          <category> encironment </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>session（会话）</title>
      <link href="/haze/2020/07/02/web/session/"/>
      <url>/haze/2020/07/02/web/session/</url>
      
        <content type="html"><![CDATA[<h2 id="session"><a href="#session" class="headerlink" title="session"></a>session</h2><p>   参考自：<a href="https://blog.csdn.net/J080624/article/details/78562787" target="_blank" rel="noopener">https://blog.csdn.net/J080624/article/details/78562787</a><br>   代码将在Advanced-Study 项目进行练习</p><h3 id="1-什么是session"><a href="#1-什么是session" class="headerlink" title="1.什么是session"></a>1.什么是session</h3><p>Cookie是存储在客户端方，Session是存储在服务端方，客户端只存储SessionId。</p><p>Session是另一种记录客户状态的机制，不同的是Cookie保存在客户端浏览器中，而Session保存在服务器上(内存或硬盘)。一般Session存储在服务器的内存中，tomcat的StandardManager类将session存储在内存中，也可以持久化到file，数据库，memcache，redis等。<br>客户端只保存sessionid到cookie中，而不会保存session，session销毁只能通过invalidate或超时(默认30分钟)，关掉浏览器并不会关闭session。</p><p>客户端浏览器访问服务器的时候，服务器把客户端信息以类似于散列表的形式记录在服务器上，这就是Session。客户端浏览器再次访问时只需要从该Session中查找该客户的状态就可以了。</p><p>服务端创建一个session前，会先判断客户端发起的请求中是否包含session标识（sessionId），若不包含，则为此用户创建一个session并生成一个与次session相关的sessionId返回给客户端。</p><h3 id="2-session的使用及读取"><a href="#2-session的使用及读取" class="headerlink" title="2.session的使用及读取"></a>2.session的使用及读取</h3><p>   Session对应的类为javax.servlet.http.HttpSession类。</p><p>   每个来访者对应一个Session对象，所有该客户的状态信息都保存在这个Session对象里。</p><p>   Session对象是在客户端第一次请求服务器的时候创建的。</p><p>   Session也是一种key-value的属性对，通过getAttribute(Stringkey)和setAttribute(String key，Objectvalue)方法读写客户状态信息。</p><p>   Servlet里通过request.getSession()方法获取该客户的Session。</p><pre><code>// 创建sessionHttpSession session = request.getSession();//设置属性session.setAttribute(&quot;name&quot;,&quot;tom&quot;);//读取属性session.getAttribute(&quot;name&quot;);//移除属性session.removeAttribute(&quot;name&quot;);//设置有效期，单位为秒，-1代表永不过期session.setMaxInactiveInterval(1000);//使其失效session.invalidate();</code></pre><p>   request还可以使用getSession(boolean create)来获取Session。</p><pre><code>getSession(true)//先创建再返回getSession(false)//返回nullgetSession()//先创建再返回</code></pre><p>   <strong>这里写两个接口来测试session</strong></p><pre><code>@RequestMapping(&quot;/testSession&quot;)public String sessionRequest(HttpSession session){    session.setAttribute(&quot;testSession&quot;,&quot;this is a session&quot;);    return &quot;session&quot;;}@RequestMapping(&quot;/getSession&quot;)public String getSession(HttpSession session){    Object sessionValue = session.getAttribute(&quot;testSession&quot;);    return String.valueOf(sessionValue);}</code></pre><h4 id="1-、第一次请求，不携带session信息，服务端生成session，会在返回中带有sessionId。"><a href="#1-、第一次请求，不携带session信息，服务端生成session，会在返回中带有sessionId。" class="headerlink" title="(1)、第一次请求，不携带session信息，服务端生成session，会在返回中带有sessionId。"></a>(1)、第一次请求，不携带session信息，服务端生成session，会在返回中带有sessionId。</h4><p><img src="/haze/2020/07/02/web/session/session01.png" alt="第一次请求"></p><h4 id="2-、第二次请求，携带sessionId，返回中不再带有session相关信息"><a href="#2-、第二次请求，携带sessionId，返回中不再带有session相关信息" class="headerlink" title="(2)、第二次请求，携带sessionId，返回中不再带有session相关信息"></a>(2)、第二次请求，携带sessionId，返回中不再带有session相关信息</h4><p><img src="/haze/2020/07/02/web/session/session02.png" alt="第二次请求"></p><h4 id="2-、第三次请求，带有sessionId，调用接口查询session中的信息"><a href="#2-、第三次请求，带有sessionId，调用接口查询session中的信息" class="headerlink" title="(2)、第三次请求，带有sessionId，调用接口查询session中的信息"></a>(2)、第三次请求，带有sessionId，调用接口查询session中的信息</h4><p><img src="/haze/2020/07/02/web/session/session03.png" alt="第三次请求"></p><h3 id="3-session的生命周期"><a href="#3-session的生命周期" class="headerlink" title="3.session的生命周期"></a>3.session的生命周期</h3><p><strong>Session在用户第一次访问服务器的时候自动创建</strong>。</p><p>   需要注意只有访问JSP、Servlet等程序时才会创建Session，只访问HTML、IMAGE等静态资源并不会创建Session。如果尚未生成Session，也可以使用request.getSession(true)强制生成Session。</p><p><strong>做如下解释说明</strong></p><ol><li><p>session是服务器建立的，但服务器不会主动建立。当一个请求过来时，服务器并不会建立一个session,而是要这样：request.getSession();当我们用程序通知服务器时它才会建立一个会话。</p></li><li><p>在jsp文件中有一个默认的属性 &lt;%@ page session=“true” %&gt;,翻译成java后就是： session = pageContext.getSession();</p></li><li><p>所以当我们访问一个jsp文件的时候，如果没有去更改这个默认值，那也会建立一个会话，这也是大多数人会认为自动创建session的原因了，其实还是相当于我们主动通知服务器去创建。</p></li><li><p>综上所述：Tomcat这类服务器不会自动的创建session,只有当我们主动通知它时，才会创建会话</p></li></ol><p>   Session生成后，只要用户继续访问，服务器就会更新Session的最后访问时间，并维护该Session。用户每访问服务器一次，无论是否读写Session，服务器都认为该用户的Session“活跃（active）”了一次。</p><p>   由于会有越来越多的用户访问服务器，因此Session也会越来越多。为防止内存溢出，服务器会把长时间内没有活跃的Session从内存删除。这个时间就是Session的超时时间。如果超过了超时时间没访问过服务器，Session就自动失效了。</p><p>   Session的超时时间为maxInactiveInterval属性<br>   默认有效期为30分钟，30分钟内没有”活跃”则失效。如果”活跃”则重新计算生命周期。</p><pre><code>//默认 time 1800int time = session.getMaxInactiveInterval();session.setMaxInactiveInterval(Integer.MAX_VALUE);</code></pre><p>   Session的超时时间也可以在web.xml中修改。另外，通过调用Session的invalidate()方法可以使Session失效。</p><p>invalidate()是指清空session对象里的东西，并不指清除这个session对象本身。所以，要判断一个session里面是否存在自己想要的东西（这个session是否有效），是不能用isNew()的，应该用如下类似代码：</p><pre><code>UserInfo userInfo=(UserInfo)session.getAttribute(”USERINFO”);if (userInfo!=null){    //...}</code></pre><p>Session需要使用Cookie作为识别标志。HTTP协议是无状态的，Session不能依据HTTP连接来判断是否为同一客户，因此服务器向客户端浏览器发送一个名为JSESSIONID的Cookie，它的值为该Session的id（也就是HttpSession.getId()的返回值）。Session依据该Cookie来识别是否为同一用户。</p><p>该Cookie为服务器自动生成的，它的maxAge属性一般为–1，表示仅当前浏览器内有效，并且不同的浏览器的窗口间不共享(同一浏览器共享)，关闭浏览器就会失效。</p><p>同一机器的两个不同类型的浏览器的窗口访问服务器时，会生成两个不同的Session。但是由浏览器窗口内的链接、脚本等打开的新窗口除外。这类子窗口会共享父窗口的Cookie，因此会共享一个Session。</p><h3 id="4-URL重写"><a href="#4-URL重写" class="headerlink" title="4.URL重写"></a>4.URL重写</h3><p>如果客户端浏览器将Cookie功能禁用，或者不支持Cookie怎么办？例如，绝大多数的手机浏览器都不支持Cookie。</p><p>Java Web提供了另一种解决方案：URL地址重写。</p><pre><code>&lt;a href=&quot;&lt;%=response.encodeUrl(url)%&gt;&quot;&gt;&lt;/a&gt;</code></pre><p>URL地址重写的原理是将该用户Session的id信息重写到URL地址中。服务器能够解析重写后的URL获取Session的id。</p><p>这样即使客户端不支持Cookie，也可以使用Session来记录用户状态。</p><p>encodeurl()方法在使用时，会首先判断Session是否启用，如果未启用，直接返回url。 然后判断客户端是否启用Cookie，如果未启用，则将参数url中加入SessionID信息，然后返回修改的URL；如果启用，直接返回参数url。</p><p><strong>注意：Tomcat判断客户端浏览器是否支持Cookie的依据是请求中是否含有Cookie。</strong></p><p>尽管客户端可能会支持Cookie，但是由于第一次请求时不会携带任何Cookie（因为并无任何Cookie可以携带），URL地址重写后的地址中仍然会带有jsessionid。</p><p>当第二次访问时服务器已经在浏览器中写入Cookie了，因此URL地址重写后的地址中就不会带有jsessionid了。</p><h3 id="5-session中禁止使用cookie"><a href="#5-session中禁止使用cookie" class="headerlink" title="5.session中禁止使用cookie"></a>5.session中禁止使用cookie</h3><p>既然WAP上大部分的客户浏览器都不支持Cookie，索性禁止Session使用Cookie，统一使用URL地址重写会更好一些。Java Web规范支持通过配置的方式禁用Cookie。</p><p>打开项目sessionWeb的WebRoot目录下的META-INF文件夹（跟WEB-INF文件夹同级，如果没有则创建），打开context.xml（如果没有则创建），编辑内容如下：</p><pre><code>/META-INF/context.xml&lt;?xml version=&#39;1.0&#39; encoding=&#39;UTF-8&#39;?&gt;&lt;Context path=&quot;/sessionWeb&quot;cookies=&quot;false&quot;&gt;&lt;/Context&gt;</code></pre><p>或者修改Tomcat全局的conf/context.xml，修改内容如下：</p><pre><code>&lt;!-- The contents of this file will be loaded for eachweb application --&gt;&lt;Context cookies=&quot;false&quot;&gt;    &lt;!-- ... 中间代码略 --&gt;&lt;/Context&gt;</code></pre><p>部署后TOMCAT便不会自动生成名JSESSIONID的Cookie，Session也不会以Cookie为识别标志，而仅仅以重写后的URL地址为识别标志了。</p><p><strong>注意：该配置只是禁止Session使用Cookie作为识别标志，并不能阻止其他的Cookie读写。也就是说服务器不会自动维护名为JSESSIONID的Cookie了，但是程序中仍然可以读写其他的Cookie。</strong></p><h3 id="6-sessionId"><a href="#6-sessionId" class="headerlink" title="6.sessionId"></a>6.sessionId</h3><p>sessionid是一个会话的key，浏览器第一次访问服务器会在服务器端生成一个session，有一个sessionid和它对应。tomcat生成的sessionid叫做jsessionid。</p><p>session在访问tomcat服务器HttpServletRequest的getSession(true)的时候创建，tomcat的ManagerBase类提供创建sessionid的方法：随机数+时间+jvmid。</p><p>其存储在服务器的内存中，tomcat的StandardManager类将session存储在内存中，也可以持久化到file，数据库，memcache，redis等。客户端只保存sessionid到cookie中，而不会保存session，session销毁只能通过invalidate或超时，关掉浏览器并不会关闭session。</p><p>session不会因为浏览器的关闭而删除。但是存有session ID的cookie的默认过期时间是会话级别。也就是用户关闭了浏览器，那么存储在客户端的session ID便会丢失，但是存储在服务器端的session数据并不会被立即删除。从客户端即浏览器看来，好像session被删除了一样（因为我们丢失了session ID，找不到原来的session数据了）。</p><h3 id="7-Session-Cookie"><a href="#7-Session-Cookie" class="headerlink" title="7.Session Cookie"></a>7.Session Cookie</h3><p>session通过SessionId来区分不同的客户，session是以cookie或url重写为基础的。默认使用cookie来实现(如果浏览器支持的话)，系统会创造一个名为JESSIONID的输出cookie，这称之为session cookie。以区别persistent cookie(也就是我们通常所说的cookie)。</p><p>session cookie是储存在浏览器内存的，并非写到硬盘上，通常看不到JESSIONID。但是当把浏览器的cookie禁用后，web服务器会采用URL重写的方式传递session id。这是地址栏将会看到。</p><p>session cookie只针对某一次会话而言，会话结束，session cookie也就跟着消失了。关闭浏览器只会使浏览器内存里的session cookie消失，但不会时服务器端的session对象消失。同样也不会使已经保存到硬盘的持久化cookie消失。</p><p>但是一旦session cookie消失，没有了session id，服务器端的原先对应的session对象也就无从分辨，相当于”失效”。</p>]]></content>
      
      
      <categories>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> session </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Cookie（缓存）</title>
      <link href="/haze/2020/07/01/web/cookie/"/>
      <url>/haze/2020/07/01/web/cookie/</url>
      
        <content type="html"><![CDATA[<h2 id="Cookie（缓存）"><a href="#Cookie（缓存）" class="headerlink" title="Cookie（缓存）"></a>Cookie（缓存）</h2><p>代码将在Advanced-Study 项目进行练习</p><h3 id="1-Cookie介绍"><a href="#1-Cookie介绍" class="headerlink" title="1.Cookie介绍"></a>1.Cookie介绍</h3><p>在了解这三个概念之前我们先要了解HTTP是无状态的Web服务器，什么是无状态呢？一次请求完成后，下一次请求完全不知道上一次请求发生了什么。如果在Web服务器中只是用来管理静态文件还好说，对方是谁并不重要，把文件从磁盘中读取出来发出去即可。但是随着网络的不断发展，比如电商中的购物车只有记住了用户的身份才能够执行接下来的一系列动作。所以此时就需要我们无状态的服务器记住一些事情。</p><p>那么Web服务器是如何记住一些事情呢？既然Web服务器记不住东西，那么我们就在外部想办法记住，相当于服务器给每个客户端都贴上了一个小纸条。上面记录了服务器给我们返回的一些信息。然后服务器看到这张小纸条就知道我们是谁了。那么Cookie是谁产生的呢？Cookies是由服务器产生的。接下来我们描述一下Cookie产生的过程。浏览器第一次访问服务端时，服务器此时肯定不知道他的身份，所以创建一个独特的身份标识数据，格式为key=value，放入到Set-Cookie字段里，随着响应报文发给浏览器。</p><ul><li><p>浏览器看到有Set-Cookie字段以后就知道这是服务器给的身份标识，于是就保存起来，下次请求时会自动将此key=value值放入到Cookie字段中发给服务端。</p></li><li><p>服务端收到请求报文后，发现Cookie字段中有值，就能根据此值识别用户的身份然后提供个性化的服务。</p></li></ul><h3 id="2-Cookie的使用"><a href="#2-Cookie的使用" class="headerlink" title="2.Cookie的使用"></a>2.Cookie的使用</h3><p>   接下来用代码演示一下，接口代码如下，cookie的key值设置为testUser</p><pre><code>@RequestMapping(&quot;/testCookies&quot;)    public String cookiesRequest(HttpServletRequest request, HttpServletResponse response){        Cookie cookie = new Cookie(&quot;testUser&quot;,&quot;cookiesUser&quot;);        response.addCookie(cookie);        return &quot;cookie&quot;;    }</code></pre><p>   访问<a href="http://localhost:8082/testCookies" target="_blank" rel="noopener">http://localhost:8082/testCookies</a> 接口，来看一下接口请求和返回，可以看到请求中未带有我们需要的缓存中，返回中带有设定好的缓存key-value。</p><p><img src="/haze/2020/07/01/web/cookie/cookie01.png" alt="请求不带缓存"></p><p>   同样的请求地址和浏览器，当我们第二次发起接口调用请求时，会发现请求中带有上一次返回的cookie值</p><p><img src="/haze/2020/07/01/web/cookie/cookie02.png" alt="请求带有缓存"></p><p>   接下来我们换一个请求呢？是不是Cookie也会带过去呢？接下来我们输入路径<a href="http://localhost:8082" target="_blank" rel="noopener">http://localhost:8082</a> 请求。我们可以看到Cookie字段还是被带过去了。</p><p><img src="/haze/2020/07/01/web/cookie/cookie03.png" alt="请求带有缓存"></p><p>   那么浏览器的Cookie是存放在哪呢？如果是使用的是Chrome浏览器的话，那么可以按照下面步骤。</p><ul><li><p>在计算机打开Chrome</p></li><li><p>在右上角，一次点击更多图标-&gt;设置</p></li><li><p>在底部，点击高级</p></li><li><p>在隐私设置和安全性下方，点击网站设置</p></li><li><p>依次点击Cookie-&gt;查看所有Cookie和网站数据</p></li></ul><table><thead><tr><th align="center">属性名</th><th align="left">描述</th></tr></thead><tbody><tr><td align="center">name</td><td align="left">Cookie的名称，Cookie一旦创建，名称便不可更改</td></tr><tr><td align="center">value</td><td align="left">Cookie的值，如果值为Unicode字符，需要为字符编码。如果为二进制数据，则需要使用BASE64编码</td></tr><tr><td align="center">maxAge</td><td align="left">Cookie失效的时间，单位秒。如果为整数，则该Cookie在maxAge秒后失效。如果为负数，该Cookie为临时Cookie，关闭浏览器即失效，浏览器也不会以任何形式保存该Cookie。如果为0，表示删除该Cookie。默认为-1。</td></tr><tr><td align="center">secure</td><td align="left">该Cookie是否仅被使用安全协议传输。安全协议。安全协议有HTTPS，SSL等，在网络上传输数据之前先将数据加密。默认为false。</td></tr><tr><td align="center">path</td><td align="left">Cookie的使用路径。如果设置为“/sessionWeb/”，则只有contextPath为“/sessionWeb”的程序可以访问该Cookie。如果设置为“/”，则本域名下contextPath都可以访问该Cookie。注意最后一个字符必须为“/”。</td></tr><tr><td align="center">domain</td><td align="left">可以访问该Cookie的域名。如果设置为“.google.com”，则所有以“google.com”结尾的域名都可以访问该Cookie。注意第一个字符必须为“.”。</td></tr><tr><td align="center">comment</td><td align="left">该Cookie的用处说明，浏览器显示Cookie信息的时候显示该说明。</td></tr><tr><td align="center">version</td><td align="left">Cookie使用的版本号。0表示遵循Netscape的Cookie规范，1表示遵循W3C的RFC 2109规范</td></tr></tbody></table><p><strong>实例路径和地址限制</strong></p><p>设置为cookie.setPath(“/testCookies”)，接下来我们访问<a href="http://localhost:8082/testCookies" target="_blank" rel="noopener">http://localhost:8082/testCookies</a>,<br>我们可以看到请求中存在cookie，而访问非/testCookies地址，则没带有cookie。这就是Path控制的路径。</p><p><strong>Domain</strong></p><p>设置为cookie.setDomain(“localhost”)，接下来我们访问<a href="http://localhost:8082/testCookies" target="_blank" rel="noopener">http://localhost:8082/testCookies</a><br>我们发现是有Cookie的字段的，但是我们访问<a href="http://172.16.42.81:8082/testCookies，" target="_blank" rel="noopener">http://172.16.42.81:8082/testCookies，</a><br>可以看到没有Cookie的字段了。这就是Domain控制的域名发送Cookie。</p><p>由于验证方式与前面一致，所以这里就不再贴图。</p>]]></content>
      
      
      <categories>
          
          <category> Web </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Cookie </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Linux 常用命令</title>
      <link href="/haze/2020/06/29/fu-wu-qi/linux-chang-yong-ming-ling/"/>
      <url>/haze/2020/06/29/fu-wu-qi/linux-chang-yong-ming-ling/</url>
      
        <content type="html"><![CDATA[<h3 id="一、权限"><a href="#一、权限" class="headerlink" title="一、权限"></a>一、权限</h3><pre><code>chown -R 用户名 文件名(文件夹名)     #更改文件所属用户chmod 777 路径+文件名（文件夹）      #文件（文件夹）赋权chmod +x test.txt                  #赋予执行权限（当前用户？）chmod -x test.txt                  #没收执行权限chmod username+x test.txt          #某用户增加执行权限chmod o+x test.txt                 #所有用户增加执行权限</code></pre><h3 id="二、编辑"><a href="#二、编辑" class="headerlink" title="二、编辑"></a>二、编辑</h3><pre><code>vi 文件名                           #编辑文件，已存在则修改，未存在则自动创建vi /etc/profile                    #编辑linux环境变量export KAFKA_HOME=/DATA/software/kafka_2.11-2.0.1    #引入环境变量source /etc/profile                #让修改后的环境变量立即生效tar xvfz m.tar.gz                  #linux解压安装包ls &gt; cmd.txt                       #重定向  把命令的结果，重新写到文件里，会覆盖已有的内容ls &gt;&gt; cmd.txt                      #向文件中追加内容ps -ef|grep redis                  #查找redis进程man bash | col -b &gt; bash.txt       #过滤控制字符，解决乱码grep ok test.txt                  #查找test.txt文件中的ok字段</code></pre><h3 id="三、查找-查看-开启"><a href="#三、查找-查看-开启" class="headerlink" title="三、查找/查看/开启"></a>三、查找/查看/开启</h3><pre><code>ps -ef|grep 应用名称                 #得到(进程)进程号ls -l /proc/进程号/cwd               #得到 服务/进程 的路径history |grep 命令（应用）           #查找命令中含有“命令”的历史记录date                                #显示系统日期uname -r                            #显示正在使用的内核版本more 文件名                          #查看文件内容tail -300f 文件名                    #动态查看最近300行日志chkconfig --list                    #显示所有自动应用chkconfig vsftpd on                 #开启自动启动ls -l | grep &quot;^d&quot;                  #只列出目录rpm -qa                            #列出系统所有安装包df /home                           #查看挂载点which java                         #查找命令在哪个目录env                                #查看环境变量</code></pre><h3 id="四、磁盘"><a href="#四、磁盘" class="headerlink" title="四、磁盘"></a>四、磁盘</h3><pre><code>df -h  /  df -lh                     #查看系统各目录磁盘空间及使用情况du -h --max-depth=1                  #查看当前目录下各文件所占磁盘空间情况top                                  #top命令是Linux下常用的性能分析工具，能够实时显示系统中各个进程的资源占用状况，类似于Windows的任务管理器。退出 top 的命令为 q （在 top 运行中敲 q 键一次）。du -s -h ./*                         #查看当前目录下各文件所占磁盘空间情况du -sh *| sort -hr                   #当前目录下占用磁盘空间大小排序</code></pre><h3 id="五、内存"><a href="#五、内存" class="headerlink" title="五、内存"></a>五、内存</h3><pre><code>top -d 1                             #监控内存，然后shift+m内存排列free -g                              #查看内存使用，单位为gfree -m                              #查看内存使用，单位Mgrep MemTotal /proc/meminfo | cut -f2 -d:     #查看服务器总内存，单位kbgrep MemTotal /proc/meminfo          #查看服务器总内存，单位kb</code></pre><h3 id="六、系统命令"><a href="#六、系统命令" class="headerlink" title="六、系统命令"></a>六、系统命令</h3><pre><code>reboot                               #重启系统shutdown -r now                      #重启系统logout                               #注销登陆shutdown -h now                      #关闭系统date 041217002007.00                 #设置日期和时间 - 月日时分年.秒</code></pre><h3 id="七、防火墙"><a href="#七、防火墙" class="headerlink" title="七、防火墙"></a>七、防火墙</h3><pre><code>service iptables stop                #关闭防火墙systemctl stop                       #关闭防火墙firewalld.services                   #关闭防火墙service iptables starts              #打开防火墙systemctl start                      #打开防火墙iptables.services                    #打开防火墙service iptables restart             #重启防火墙systemctl start                      #重启防火墙ip6tables.service                    #重启防火墙systemctl status firewalld          #查看防火墙状态systemctl disable firewalld         #开机禁用systemctl enable firewalld          #开机自启</code></pre><h3 id="八、TCP"><a href="#八、TCP" class="headerlink" title="八、TCP"></a>八、TCP</h3><pre><code>netstat -an | grep ESTABLISHED | wc -l       #查看apache当前并发访问数netstat -anp|more                            #显示整个系统目前的网络情况。例如目前的连接、数据包传递数据、或是路由表内容。netstat -tunlp|grep 5601                     #查找5601端口占用进程id</code></pre><h3 id="九、CPU"><a href="#九、CPU" class="headerlink" title="九、CPU"></a>九、CPU</h3><h4 id="总核数-物理CPU个数-X-每颗物理CPU的核数"><a href="#总核数-物理CPU个数-X-每颗物理CPU的核数" class="headerlink" title="总核数 = 物理CPU个数 X 每颗物理CPU的核数"></a>总核数 = 物理CPU个数 X 每颗物理CPU的核数</h4><h4 id="总逻辑CPU数-物理CPU个数-X-每颗物理CPU的核数-X-超线程数"><a href="#总逻辑CPU数-物理CPU个数-X-每颗物理CPU的核数-X-超线程数" class="headerlink" title="总逻辑CPU数 = 物理CPU个数 X 每颗物理CPU的核数 X 超线程数"></a>总逻辑CPU数 = 物理CPU个数 X 每颗物理CPU的核数 X 超线程数</h4><pre><code>cat /proc/cpuinfo| grep &quot;physical id&quot;| sort| uniq| wc -l        #查看物理CPU个数cat /proc/cpuinfo| grep &quot;cpu cores&quot;| uniq                       #查看每个物理CPU中core的个数(即核数)cat /proc/cpuinfo| grep &quot;processor&quot;| wc -l                      #查看逻辑CPU的个数cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c           #查看CPU信息（型号）vmstat 1                                                        #监控CPU.top                                                             #监控进程more /proc/cpuinfo | grep &quot;model name&quot;                          #查看cpugrep &quot;model name&quot; /proc/cpuinfo                                 #查看cpugrep &quot;model name&quot; /proc/cpuinfo | cut -f2 -d:                   #查看cpugetconf LONG_BIT                                               #查看CPU位数(32 or 64)</code></pre><h3 id="十、用户相关"><a href="#十、用户相关" class="headerlink" title="十、用户相关"></a>十、用户相关</h3><pre><code>useradd username              #创建用户（新创建的用户会在/home下创建一个用户目录incredible-test）passwd username               #给已创建的用户设置密码usermod --help                #修改用户这个命令的相关参数userdel username              #删除用户groupadd groupname            #添加组groupdel groupname            #删除组su username                   #切换登陆用户,exit退出到root账户？rm -rf /home/usernmae         #删除用户后，删除该用户目录passwd                        #登陆root账户情况下，修改root密码passwd username              #修改用户密码useradd username -g groupname     #指定用户到某个组usermod -g groupname username     #修改用户所在组whoami                            #查看当前登陆的用户</code></pre>]]></content>
      
      
      <categories>
          
          <category> Linux </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TIG搭建</title>
      <link href="/haze/2020/06/26/environment/tig-da-jian/tig/"/>
      <url>/haze/2020/06/26/environment/tig-da-jian/tig/</url>
      
        <content type="html"><![CDATA[<h2 id="TIG监控"><a href="#TIG监控" class="headerlink" title="TIG监控"></a>TIG监控</h2><p>TIG监控是一种硬件、业务数据监控组件，主要用于监控服务器状态及业务数据量、时间等信息。</p><ul><li><p>Influxdb:一种时序性数据库，主要用于存储数据</p></li><li><p>Telegraf：收集数据组件，本实验中用于收集硬件、业务指标</p></li><li><p>Grafana：用于实时展示收集到的指标数据</p></li></ul><h4 id="这里选择在目录-opt-app-TIG下进行"><a href="#这里选择在目录-opt-app-TIG下进行" class="headerlink" title="这里选择在目录/opt/app/TIG下进行"></a>这里选择在目录/opt/app/TIG下进行</h4><h3 id="一、influxdb"><a href="#一、influxdb" class="headerlink" title="一、influxdb"></a>一、influxdb</h3><h4 id="1-解压安装包-将安装包放到目录下-："><a href="#1-解压安装包-将安装包放到目录下-：" class="headerlink" title="1.解压安装包(将安装包放到目录下)："></a>1.解压安装包(将安装包放到目录下)：</h4><pre><code>cd /opt/app/TIG(或者其他服务器上传目录下)tar -xvzf influxdb-1.2.0_linux_amd64.tar.gzcd influxdb-1.2.0-1</code></pre><h4 id="2-查看InfluxDB默认端口8083-8086端口是否被占用，若未占用，则无信息返回"><a href="#2-查看InfluxDB默认端口8083-8086端口是否被占用，若未占用，则无信息返回" class="headerlink" title="2.查看InfluxDB默认端口8083,8086端口是否被占用，若未占用，则无信息返回"></a>2.查看InfluxDB默认端口8083,8086端口是否被占用，若未占用，则无信息返回</h4><pre><code> lsof -i:8083 lsof -i:8086</code></pre><h4 id="3-如果未占用-则如下修改配置文件-否则修改为其他端口号"><a href="#3-如果未占用-则如下修改配置文件-否则修改为其他端口号" class="headerlink" title="3.如果未占用,则如下修改配置文件.否则修改为其他端口号"></a>3.如果未占用,则如下修改配置文件.否则修改为其他端口号</h4><pre><code>vi etc/influxdb/influxdb.conf</code></pre><h4 id="4-将admin下的enabled与bind-address修改为如下-："><a href="#4-将admin下的enabled与bind-address修改为如下-：" class="headerlink" title="4.将admin下的enabled与bind-address修改为如下.："></a>4.将admin下的enabled与bind-address修改为如下.：</h4><pre><code>[admin]   # Determines whether the admin service is enabled.   enabled = true   # The default bind address used by the admin service.   bind-address = &quot;:8083&quot;   # Whether the admin service should use HTTPS.   # https-enabled = false   # The SSL certificate used when HTTPS is enabled.   # https-certificate = &quot;/etc/ssl/influxdb.pem&quot;</code></pre><h4 id="5-启动influxdb"><a href="#5-启动influxdb" class="headerlink" title="5.启动influxdb"></a>5.启动influxdb</h4><pre><code>nohup usr/bin/influxd -config etc/influxdb/influxdb.conf &amp;</code></pre><h4 id="6-查看influxdb进程是否正常启动"><a href="#6-查看influxdb进程是否正常启动" class="headerlink" title="6.查看influxdb进程是否正常启动"></a>6.查看influxdb进程是否正常启动</h4><pre><code>ps aux|grep influxdb</code></pre><h4 id="7-在本地访问：http-ip-8083"><a href="#7-在本地访问：http-ip-8083" class="headerlink" title="7.在本地访问：http://ip:8083/"></a>7.在本地访问：<a href="http://ip:8083/" target="_blank" rel="noopener">http://ip:8083/</a></h4><p>   ip为linux服务器对外映射的ip</p><p>####问题及注意：</p><ul><li><p>添加虚拟机ip访问的代理忽略（即本地访问不使用代理）</p></li><li><p>若未安装lsof命令，则运行sudo yum install lsof进行安装</p></li></ul><h3 id="二、telegraf"><a href="#二、telegraf" class="headerlink" title="二、telegraf"></a>二、telegraf</h3><h4 id="1-解压安装包"><a href="#1-解压安装包" class="headerlink" title="1.解压安装包"></a>1.解压安装包</h4><pre><code>cd /opt/app/TIG(或者自定义上传目录下)tar -xzvf telegraf-1.6.1_linux_amd64.tar.gzcd telegraf</code></pre><h4 id="2-修改配置文件，将收集的信息放入刚才安装的influxd数据库"><a href="#2-修改配置文件，将收集的信息放入刚才安装的influxd数据库" class="headerlink" title="2.修改配置文件，将收集的信息放入刚才安装的influxd数据库"></a>2.修改配置文件，将收集的信息放入刚才安装的influxd数据库</h4><pre><code>vi etc/telegraf/telegraf.conf# 修改的节点为outputs.influxdb下的urls和database配置如下(P.S:IP改为InfluxDB部署服务器的IP地址)[[outputs.influxdb]]   ## The full HTTP or UDP URL for your InfluxDB instance.   ##   ## Multiple URLs can be specified for a single cluster, only ONE of the   ## urls will be written to each interval.   # urls = [&quot;unix:///var/run/influxdb.sock&quot;]   # urls = [&quot;udp://127.0.0.1:8089&quot;]   urls = [&quot;http://10.221.155.69:8086&quot;]   ## The target database for metrics; will be created as needed.   database = &quot;telegraf&quot;</code></pre><h4 id="3-启动telegraf，并查看进程是否正常运行"><a href="#3-启动telegraf，并查看进程是否正常运行" class="headerlink" title="3.启动telegraf，并查看进程是否正常运行"></a>3.启动telegraf，并查看进程是否正常运行</h4><pre><code>usr/bin/telegraf -config etc/telegraf/telegraf.conf &amp;ps aux|grep telegraf</code></pre><h4 id="4-验证telegraf是否将硬件指标插入influxdb数据库"><a href="#4-验证telegraf是否将硬件指标插入influxdb数据库" class="headerlink" title="4.验证telegraf是否将硬件指标插入influxdb数据库"></a>4.验证telegraf是否将硬件指标插入influxdb数据库</h4><p>   访问inflxudb admin页面<a href="http://influxdb的ip地址:8083/" target="_blank" rel="noopener">http://influxdb的ip地址:8083/</a></p><h4 id="5-查看插入的表信息（页面query栏输入）"><a href="#5-查看插入的表信息（页面query栏输入）" class="headerlink" title="5.查看插入的表信息（页面query栏输入）"></a>5.查看插入的表信息（页面query栏输入）</h4><pre><code>   SHOW MEASUREMENTS</code></pre><h4 id="6-查看CPU信息（页面query栏输入）"><a href="#6-查看CPU信息（页面query栏输入）" class="headerlink" title="6.查看CPU信息（页面query栏输入）"></a>6.查看CPU信息（页面query栏输入）</h4><pre><code>select * from cpu order by time desc limit 10</code></pre><h4 id="收集业务指标"><a href="#收集业务指标" class="headerlink" title="收集业务指标"></a>收集业务指标</h4><p> 业务场景：将日志文件：/opt/applog/influxdb.log的内容收集到influxdb数据库中。</p><h4 id="7-新增telegraf业务指标配置文件"><a href="#7-新增telegraf业务指标配置文件" class="headerlink" title="7.新增telegraf业务指标配置文件"></a>7.新增telegraf业务指标配置文件</h4><pre><code>    vi etc/telegraf/telegraf_tail.conf</code></pre><h4 id="8-配置文件内容如下-P-S-IP改为InfluxDB部署服务器的IP地址"><a href="#8-配置文件内容如下-P-S-IP改为InfluxDB部署服务器的IP地址" class="headerlink" title="8.配置文件内容如下(P.S:IP改为InfluxDB部署服务器的IP地址):"></a>8.配置文件内容如下(P.S:IP改为InfluxDB部署服务器的IP地址):</h4><pre><code>       [[outputs.influxdb]]          urls = [&quot;http://ip:8086&quot;]          database = &quot;tail&quot;          precision = &quot;s&quot;          timeout = &quot;5s&quot;          username = &quot;root&quot;          password = &quot;root&quot;        [[inputs.tail]]          ## files to tail.          ## These accept standard unix glob matching rules, but with the addition of          ## ** as a &quot;super asterisk&quot;. ie:          ##   &quot;/var/log/**.log&quot;  -&gt; recursively find all .log files in /var/log          ##   &quot;/var/log/*/*.log&quot; -&gt; find all .log files with a parent dir in /var/log          ##   &quot;/var/log/apache.log&quot; -&gt; just tail the apache log file          ##          ## See https://github.com/gobwas/glob for more examples          ##          files = [&quot;/opt/applog/influxdb.log&quot;]          ## Read file from beginning.          from_beginning = false          ## Whether file is a named pipe          pipe = false          ## Method used to watch for file updates.  Can be either &quot;inotify&quot; or &quot;poll&quot;.          watch_method = &quot;poll&quot;          ## Data format to consume.          ## Each data format has its own unique set of configuration options, read          ## more about them here:          ## https://github.com/influxdata/telegraf/blob/master/docs/DATA_FORMATS_INPUT.md          data_format = &quot;influx&quot;</code></pre><h4 id="9-新增一条业务日志"><a href="#9-新增一条业务日志" class="headerlink" title="9.新增一条业务日志"></a>9.新增一条业务日志</h4><pre><code>echo &#39;testtable,ip=127.0.0.1,user=taobao,service=airbook servicetime=31&#39;  &gt;&gt; /opt/applog/influxdb.log</code></pre><h4 id="10-启动telegraf-并查看进程是否正常启动"><a href="#10-启动telegraf-并查看进程是否正常启动" class="headerlink" title="10.启动telegraf,并查看进程是否正常启动"></a>10.启动telegraf,并查看进程是否正常启动</h4><pre><code>usr/bin/telegraf -config etc/telegraf/telegraf_tail.conf &amp;ps aux|grep telegraf</code></pre><h4 id="11-验证业务日志是否插入到influxdb中"><a href="#11-验证业务日志是否插入到influxdb中" class="headerlink" title="11.验证业务日志是否插入到influxdb中"></a>11.验证业务日志是否插入到influxdb中</h4><p>   访问inflxudb admin页面<a href="http://influxDB的ip地址:8083/" target="_blank" rel="noopener">http://influxDB的ip地址:8083/</a></p><h4 id="12-查看插入的表信息"><a href="#12-查看插入的表信息" class="headerlink" title="12.查看插入的表信息"></a>12.查看插入的表信息</h4><pre><code>SHOW MEASUREMENTS</code></pre><h4 id="13-查看表信息"><a href="#13-查看表信息" class="headerlink" title="13.查看表信息"></a>13.查看表信息</h4><pre><code>select * from testtable order by time desc limit 10</code></pre><h3 id="三、安装grafana"><a href="#三、安装grafana" class="headerlink" title="三、安装grafana"></a>三、安装grafana</h3><h4 id="1-解压安装包："><a href="#1-解压安装包：" class="headerlink" title="1.解压安装包："></a>1.解压安装包：</h4><pre><code> cd /opt/app/TIG(或者本机上传目录下) tar -zxvf grafana-4.2.0.linux-x64.tar.gz cd grafana-4.2.0</code></pre><h4 id="2-启动grafana-并检查进程是否正常启动"><a href="#2-启动grafana-并检查进程是否正常启动" class="headerlink" title="2.启动grafana,并检查进程是否正常启动"></a>2.启动grafana,并检查进程是否正常启动</h4><pre><code>bin/grafana-server &amp;ps aux|grep grafana</code></pre><h4 id="3-验证grafana是否能正常访问"><a href="#3-验证grafana是否能正常访问" class="headerlink" title="3.验证grafana是否能正常访问"></a>3.验证grafana是否能正常访问</h4><p>   <a href="http://grafana的ip地址:3000/login" target="_blank" rel="noopener">http://grafana的ip地址:3000/login</a></p><h4 id="4-登录grafana"><a href="#4-登录grafana" class="headerlink" title="4.登录grafana"></a>4.登录grafana</h4><p>默认账户：admin   密码：admin<br>备注：账户密码可配置，配置文件路径：conf/defaults.ini</p><h4 id="5-新增硬件DataSource（配置数据库）访问地址："><a href="#5-新增硬件DataSource（配置数据库）访问地址：" class="headerlink" title="5.新增硬件DataSource（配置数据库）访问地址："></a>5.新增硬件DataSource（配置数据库）访问地址：</h4><p><a href="http://192.168.56.1:3000/datasources/new" target="_blank" rel="noopener">http://192.168.56.1:3000/datasources/new</a></p><p><img src="/haze/2020/06/26/environment/tig-da-jian/tig/grafana1.png" alt="grafana 1"><br></p><p><img src="/haze/2020/06/26/environment/tig-da-jian/tig/grafana2.png" alt="grafana 2"><br></p><h4 id="6-新增CPU看板（dashboard）访问地址："><a href="#6-新增CPU看板（dashboard）访问地址：" class="headerlink" title="6.新增CPU看板（dashboard）访问地址："></a>6.新增CPU看板（dashboard）访问地址：</h4><p>   <a href="http://192.168.56.1:3000/dashboard/new?orgId=1" target="_blank" rel="noopener">http://192.168.56.1:3000/dashboard/new?orgId=1</a></p><p><img src="/haze/2020/06/26/environment/tig-da-jian/tig/grafana3.png" alt="grafana 3"><br></p><p><img src="/haze/2020/06/26/environment/tig-da-jian/tig/grafana4.png" alt="grafana 4"><br></p>]]></content>
      
      
      <categories>
          
          <category> encironment </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> TIG </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>ELK搭建</title>
      <link href="/haze/2020/06/22/environment/elk-da-jian/elk/"/>
      <url>/haze/2020/06/22/environment/elk-da-jian/elk/</url>
      
        <content type="html"><![CDATA[<h2 id="ELK"><a href="#ELK" class="headerlink" title="ELK"></a>ELK</h2><p>ELK由elasticsearch（存储层）、logstash（收集）、kibana（展示）三部分组成，三个组件的版本建议保持一致。此文档是基于ELK7.6.2版本，其余版本在配置上可能会有差异。</p><table><thead><tr><th>ip地址</th><th>应用</th></tr></thead><tbody><tr><td>netip1</td><td>es</td></tr><tr><td>netip2</td><td>es</td></tr><tr><td>netip3</td><td>kibana</td></tr><tr><td>netip4</td><td>logstash 业务日志收集</td></tr><tr><td>netip5</td><td>logstash 防火墙日志收集</td></tr></tbody></table><h3 id="elasticsearch"><a href="#elasticsearch" class="headerlink" title="elasticsearch"></a>elasticsearch</h3><p>主要介绍es的搭建，没有采用docker进行搭建，后续再加上docker搭建的文档</p><h4 id="一、环境准备"><a href="#一、环境准备" class="headerlink" title="一、环境准备"></a>一、环境准备</h4><h5 id="1、下载es的安装包，上传至服务器，或者在服务器直接使用命令下载。"><a href="#1、下载es的安装包，上传至服务器，或者在服务器直接使用命令下载。" class="headerlink" title="1、下载es的安装包，上传至服务器，或者在服务器直接使用命令下载。"></a>1、下载es的安装包，上传至服务器，或者在服务器直接使用命令下载。</h5><p>这里给出当前最新版本安装包<br>   <a href="https://www.elastic.co/cn/downloads/elasticsearch" target="_blank" rel="noopener">点击下载es</a></p><h5 id="2、es是基于java环境的，所以安装es前需要先配置jdk，这里配置的是jdk8。7-6的es要求是jdk11以上，但他是向下兼容的，所以jdk8即可。java环境的配置是基本操作这里就不赘述了。"><a href="#2、es是基于java环境的，所以安装es前需要先配置jdk，这里配置的是jdk8。7-6的es要求是jdk11以上，但他是向下兼容的，所以jdk8即可。java环境的配置是基本操作这里就不赘述了。" class="headerlink" title="2、es是基于java环境的，所以安装es前需要先配置jdk，这里配置的是jdk8。7.6的es要求是jdk11以上，但他是向下兼容的，所以jdk8即可。java环境的配置是基本操作这里就不赘述了。"></a>2、es是基于java环境的，所以安装es前需要先配置jdk，这里配置的是jdk8。7.6的es要求是jdk11以上，但他是向下兼容的，所以jdk8即可。java环境的配置是基本操作这里就不赘述了。</h5><h5 id="3、搭建2台es作为集群吧，先准备两台服务器-虚拟机（net1，net2【这里用netip1、netip2代替ip地址】）"><a href="#3、搭建2台es作为集群吧，先准备两台服务器-虚拟机（net1，net2【这里用netip1、netip2代替ip地址】）" class="headerlink" title="3、搭建2台es作为集群吧，先准备两台服务器/虚拟机（net1，net2【这里用netip1、netip2代替ip地址】）"></a>3、搭建2台es作为集群吧，先准备两台服务器/虚拟机（net1，net2【这里用netip1、netip2代替ip地址】）</h5><h4 id="二、编辑es配置"><a href="#二、编辑es配置" class="headerlink" title="二、编辑es配置"></a>二、编辑es配置</h4><p>1、创建文件夹</p><pre><code>--创建elk的文件夹mkdir /opt/elk-- 存放es的数据mkdir /opt/elk/data/es/data-- 存放es的日志mkdir /opt/elk/data/es/logs-- 将目录权限赋值给非root用户，非root用户创建请忽略chown -R prouser /opt/elk</code></pre><h5 id="2、解压文件并重命名"><a href="#2、解压文件并重命名" class="headerlink" title="2、解压文件并重命名"></a>2、解压文件并重命名</h5><pre><code>tar zvxf elasticsearch-7.6.2-linux-x86_64.tar.gzmv elasticsearch-7.6.2  elasticsearch</code></pre><h5 id="3、编辑配置文件"><a href="#3、编辑配置文件" class="headerlink" title="3、编辑配置文件"></a>3、编辑配置文件</h5><pre><code>-- 先进入根目录cd elasticsearchvi config/elasticsearch.yml</code></pre><h5 id="4、配置文件需要配置的内容如下-两个服务器配置只有nodename和ip不同"><a href="#4、配置文件需要配置的内容如下-两个服务器配置只有nodename和ip不同" class="headerlink" title="4、配置文件需要配置的内容如下,两个服务器配置只有nodename和ip不同"></a>4、配置文件需要配置的内容如下,两个服务器配置只有nodename和ip不同</h5><pre><code>-- 集群设置，es会默认将相同网段的es作为集群，当有多个集群时，通过该字段进行区分cluster.name: dp-es-- 节点名称，集群必须定义，单台可不用定义node.name: dp-122path.data: /opt/elk/data/es/datapath.logs: /opt/elk/data/es/logsnetwork.host: netip1http.port: 9200-- 可以作为master的节点，集群必不可少cluster.initial_master_nodes: [&quot;netip1&quot;,&quot;netip2&quot;]-- 可以初始化的节点，集群必不可少discovery.seed_hosts: [&quot;netip1&quot;,&quot;netip2&quot;]-- 检测到几个节点时开始恢复数据gateway.recover_after_nodes: 1-- 跨域设置，这个选择性设置，非必要http.cors.enabled: truehttp.cors.allow-origin: &quot;*&quot;</code></pre><h4 id="三、启动es前的准备"><a href="#三、启动es前的准备" class="headerlink" title="三、启动es前的准备"></a>三、启动es前的准备</h4><p>es对环境有比较高的要求，现对服务器做如下配置：<br></p><pre><code>-- 1、切换至root用户su root-- 2、编辑打开文件数限制vi /etc/security/limits.conf-- 编辑如下内容，注意*号不要复制掉了* soft nofile 65536* hard nofile 65536-- 3、更改vmecho &#39;vm.max_map_count=262144&#39;&gt;&gt; /etc/sysctl.conf-- 查看更改sysctl -p-- 4、编辑限制vi /etc/security/limits.d/90-nproc.conf-- 内容如下* soft nproc 4096</code></pre><h4 id="四、启动es"><a href="#四、启动es" class="headerlink" title="四、启动es"></a>四、启动es</h4><h5 id="1、依次启动es，注意观察启动日志。"><a href="#1、依次启动es，注意观察启动日志。" class="headerlink" title="1、依次启动es，注意观察启动日志。"></a>1、依次启动es，注意观察启动日志。</h5><pre><code>-- 进入es根目录，先控制台启动bin/elasticsearch-- 无问题再切换为后台启动nohup bin/elasticsearch &gt;/dev/null 2&gt;&amp;1 &amp;</code></pre><h5 id="2、确认es是否启动"><a href="#2、确认es是否启动" class="headerlink" title="2、确认es是否启动"></a>2、确认es是否启动</h5><p>(1)、命令确认：</p><pre><code>curl -X GET http://netip1:9200</code></pre><p>(2)、访问页面 <a href="http://netip1:9200" target="_blank" rel="noopener">http://netip1:9200</a> <br></p><p>返回如下情况则表示安装成功：</p><p><img src="/haze/2020/06/22/environment/elk-da-jian/elk/es-return.png" alt="build succes"><br></p><h4 id="五、可能会出现严重错误导致无法启动"><a href="#五、可能会出现严重错误导致无法启动" class="headerlink" title="五、可能会出现严重错误导致无法启动"></a>五、可能会出现严重错误导致无法启动</h4><p>可能会出现如下错误，导致无法启动：</p><p><img src="/haze/2020/06/22/environment/elk-da-jian/elk/es-error01.png" alt="build error"><br></p><pre><code>-- 跳过filterbootstrap.memory_lock: falsebootstrap.system_call_filter: false</code></pre><h3 id="kibana"><a href="#kibana" class="headerlink" title="kibana"></a>kibana</h3><p>这段将介绍简单的搭建kibana</p><h4 id="一、环境准备-1"><a href="#一、环境准备-1" class="headerlink" title="一、环境准备"></a>一、环境准备</h4><h5 id="1、下载kibana的安装包，上传至服务器，或者在服务器直接使用命令下载。"><a href="#1、下载kibana的安装包，上传至服务器，或者在服务器直接使用命令下载。" class="headerlink" title="1、下载kibana的安装包，上传至服务器，或者在服务器直接使用命令下载。"></a>1、下载kibana的安装包，上传至服务器，或者在服务器直接使用命令下载。</h5><p>这里给出当前最新版本安装包<br><br><a href="https://www.elastic.co/cn/downloads/kibana" target="_blank" rel="noopener">点击下载kibana</a></p><h5 id="2、需要一台服务器-虚拟机，这里就放在netip3"><a href="#2、需要一台服务器-虚拟机，这里就放在netip3" class="headerlink" title="2、需要一台服务器/虚拟机，这里就放在netip3"></a>2、需要一台服务器/虚拟机，这里就放在netip3</h5><h4 id="二、编辑kibana配置"><a href="#二、编辑kibana配置" class="headerlink" title="二、编辑kibana配置"></a>二、编辑kibana配置</h4><h5 id="1、解压文件并重命名"><a href="#1、解压文件并重命名" class="headerlink" title="1、解压文件并重命名"></a>1、解压文件并重命名</h5><pre><code>cd /opt/elktar zvxf kibana-7.6.2-linux-x86_64.tar.gzmv kibana-7.6.2 kibana</code></pre><h5 id="2、-配置kibana文件"><a href="#2、-配置kibana文件" class="headerlink" title="2、 配置kibana文件"></a>2、 配置kibana文件</h5><pre><code>-- 配置kibanacd kibanavi config/kibana.yml</code></pre><h5 id="3、-配置内容如下"><a href="#3、-配置内容如下" class="headerlink" title="3、 配置内容如下"></a>3、 配置内容如下</h5><pre><code>server.port: 5601server.host: &quot;netip3&quot;-- es集群elasticsearch.hosts: [&quot;http://netip1:9200&quot;，&quot;http://netip2:9200&quot;]</code></pre><h4 id="三、启动kibana"><a href="#三、启动kibana" class="headerlink" title="三、启动kibana"></a>三、启动kibana</h4><pre><code>nohup bin/kibana &gt;/dev/null 2&gt;&amp;1 &amp;</code></pre><p>kinaba不依赖于java环境，所以查询只能通过端口</p><pre><code>netstat -tunlp|grep 5601</code></pre><p>确认启动成功访问kiban：<a href="http://netip3:5601" target="_blank" rel="noopener">http://netip3:5601</a></p><h3 id="Logstash"><a href="#Logstash" class="headerlink" title="Logstash"></a>Logstash</h3><p>本节简单介绍logstash的配置启动</p><h4 id="一、环境准备-2"><a href="#一、环境准备-2" class="headerlink" title="一、环境准备"></a>一、环境准备</h4><h5 id="1、logstash和es一样需要java环境，也是向下兼容的，jkd8即可"><a href="#1、logstash和es一样需要java环境，也是向下兼容的，jkd8即可" class="headerlink" title="1、logstash和es一样需要java环境，也是向下兼容的，jkd8即可."></a>1、logstash和es一样需要java环境，也是向下兼容的，jkd8即可.</h5><h5 id="2、准备服务器，至少1台，这里选取119"><a href="#2、准备服务器，至少1台，这里选取119" class="headerlink" title="2、准备服务器，至少1台，这里选取119"></a>2、准备服务器，至少1台，这里选取119</h5><h5 id="3、下载logstash"><a href="#3、下载logstash" class="headerlink" title="3、下载logstash"></a>3、下载logstash<br></h5><p><a href="https://www.elastic.co/cn/downloads/logstash" target="_blank" rel="noopener">点击下载logstash</a></p><h4 id="二、配置编辑"><a href="#二、配置编辑" class="headerlink" title="二、配置编辑"></a>二、配置编辑</h4><h5 id="1、解压并重命名"><a href="#1、解压并重命名" class="headerlink" title="1、解压并重命名"></a>1、解压并重命名</h5><pre><code>tar zvxf logstash-7.6.2.tar.gzmv logstash-7.6.2 logstash</code></pre><h5 id="2、logstash的本身配置文件无需任何更改，新建一个自定义配置-dp-logstash-conf"><a href="#2、logstash的本身配置文件无需任何更改，新建一个自定义配置-dp-logstash-conf" class="headerlink" title="2、logstash的本身配置文件无需任何更改，新建一个自定义配置:dp-logstash.conf"></a>2、logstash的本身配置文件无需任何更改，新建一个自定义配置:dp-logstash.conf</h5><pre><code>cd logstashvi /config/dp-logstash.conf</code></pre><p>这里放入119的测试环境配置，暂时只有推送和拉取模块的，将两个模块的配置放在一起进行收集，如下：</p><pre><code>input {  file {        path =&gt; &quot;/DATA/applog/dslog/datahanderinfo.log&quot;        type =&gt; &quot;obtain&quot;        codec =&gt; multiline {            pattern =&gt; &quot;^%{YEAR}&quot;            negate =&gt; true            what =&gt; &quot;previous&quot;        }    }  file {        path =&gt; &quot;/DATA/applog/dslog/pushloginfo.log&quot;        type =&gt; &quot;pushhttp&quot;        codec =&gt; multiline {            pattern =&gt; &quot;^%{YEAR}&quot;            negate =&gt; true            what =&gt; &quot;previous&quot;        }    }}filter {          if ([message] =~ &quot;collectd|SourceAddr|Priority|MsgType=|&lt;Subevent|result.isSuccess|没有获取到&quot;) {           drop {}          }          if ([type] == &quot;obtain&quot;){             mutate {                   split =&gt; { &quot;message&quot; =&gt; &quot;MsgContent=&quot; }                   add_field =&gt;   {&quot;msgcontent&quot; =&gt; &quot;%{[message][1]}&quot;}                   remove_field =&gt; [&quot;message&quot;]                   add_field =&gt;   {&quot;datatype&quot; =&gt; &quot;origindata&quot;}                   replace =&gt; { &quot;host&quot; =&gt; &quot;netip4&quot; }                 }          }          if ([type] == &quot;pushhttp&quot;){              mutate {                   split =&gt; { &quot;message&quot; =&gt; &quot;-run,&quot; }                   add_field =&gt;   {&quot;msgcontent&quot; =&gt; &quot;%{[message][1]}&quot;}                   remove_field =&gt; [&quot;message&quot;]                   replace =&gt; { &quot;host&quot; =&gt; &quot;netip4&quot; }                 }          }}output {    elasticsearch { hosts =&gt; [&quot;netip1:9200&quot;,&quot;netip2:9200&quot;]                    index =&gt; &quot;logstash-%{type}-%{+YYYY.MM.dd}&quot;}    stdout { codec=&gt; rubydebug }}</code></pre><h5 id="再附上一个防火墙系统日志的收集"><a href="#再附上一个防火墙系统日志的收集" class="headerlink" title="再附上一个防火墙系统日志的收集"></a>再附上一个防火墙系统日志的收集</h5><pre><code># 输入input{  udp{    host =&gt; &quot;netip5&quot;    port =&gt; 514    codec =&gt; line  }}# 过滤器filter {  # 拆分字段  kv {    source =&gt; &quot;message&quot;    include_keys =&gt; [&quot;src&quot;,&quot;dst&quot;,&quot;proto&quot;,&quot;sport&quot;,&quot;dport&quot;,&quot;inpkt&quot;,&quot;outpkt&quot;,&quot;sent&quot;,&quot;rcvd&quot;,&quot;duration&quot;,&quot;connid&quot;,&quot;parent&quot;,&quot;op&quot; ]  }  # 上下行流量转为Integer类型  mutate{    convert =&gt; [&quot;rcvd&quot;,&quot;integer&quot;]    convert =&gt; [&quot;sent&quot;,&quot;integer&quot;]  }  #删除无用字段,host固定为服务所在ip  mutate {    replace =&gt; { &quot;host&quot; =&gt; &quot;netip5&quot; }  }  #从源ip中获取楼层信息  grok {    match =&gt; {      &quot;src&quot; =&gt; &quot;101.26.(?&lt;floor&gt;\d)(0*).\d&quot;    }  }}# 输出output{  elasticsearch{    hosts =&gt; &quot;netip5:9200&quot;    index =&gt; &quot;netfire-%{+YYYY.MM.dd}&quot;    manage_template =&gt; false    template_name =&gt; &quot;netfire_template&quot;  }}</code></pre><h4 id="三、启动logstash"><a href="#三、启动logstash" class="headerlink" title="三、启动logstash"></a>三、启动logstash</h4><h5 id="1、-通过指定配置文件的方式启动logstash"><a href="#1、-通过指定配置文件的方式启动logstash" class="headerlink" title="1、 通过指定配置文件的方式启动logstash"></a>1、 通过指定配置文件的方式启动logstash</h5><pre><code>nohup bin/logstash -f config/dp-logstash.conf &gt;start.log 2&gt;&amp;1 &amp;</code></pre><h4 id="详细的配置请参考官方文档"><a href="#详细的配置请参考官方文档" class="headerlink" title="详细的配置请参考官方文档"></a>详细的配置请参考官方文档</h4>]]></content>
      
      
      <categories>
          
          <category> encironment </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> ELK </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>docker一键式安装脚本</title>
      <link href="/haze/2020/06/18/docker/docker-an-zhuang-jiao-ben/"/>
      <url>/haze/2020/06/18/docker/docker-an-zhuang-jiao-ben/</url>
      
        <content type="html"><![CDATA[<h2 id="docker一键式安装脚本"><a href="#docker一键式安装脚本" class="headerlink" title="docker一键式安装脚本"></a>docker一键式安装脚本</h2><p>将以下脚本拷贝至shell脚本中，附于执行权限，使用管理员身份执行即可安装docker</p><pre><code>#!/bin/bash# 环境初始化：指定用户需要有sudo权限# step 1: 移除旧的dockersudo yum remove -y docker \                docker-client \                docker-client-latest \                docker-common \                docker-latest \                docker-latest-logrotate \                docker-logrotate \                docker-selinux \                docker-engine-selinux \                docker-engine \                docker-cesudo rm -rf /var/lib/docker# step 2: 安装相关组件和配置yum源sudo yum install -y yum-utils \  device-mapper-persistent-data \  lvm2sudo yum-config-manager \    --add-repo \    http://mirrors.aliyun.com/docker-ce/linux/centos/docker-ce.repo# step 3: 配置缓存sudo yum makecache fast# step 4: 执行安装sudo yum install -y docker-ce-18.06.3.ce-3.el7****# step 5: 启动docker并配置开机启动并软连接配置镜像存储路径sudo systemctl start dockersudo systemctl enable docker# 注意路径的变更sudo mv /var/lib/docker /data/dockersudo ln -s /data/docker /var/lib/docker# step 6: 配置当前用户对docker命令的执行权限sudo groupadd dockersudo gpasswd -a ${USER} dockersudo systemctl restart docker# vim /etc/yum.repos.d/docker-ce.repo#   将[docker-ce-test]下方的enabled=0修改为enabled=1## 安装指定版本的Docker-CE:# Step 1: 查找Docker-CE的版本:# yum list docker-ce.x86_64 --showduplicates | sort -r#   Loading mirror speeds from cached hostfile#   Loaded plugins: branch, fastestmirror, langpacks#   docker-ce.x86_64            17.03.1.ce-1.el7.centos            docker-ce-stable#   docker-ce.x86_64            17.03.1.ce-1.el7.centos            @docker-ce-stable#   docker-ce.x86_64            17.03.0.ce-1.el7.centos            docker-ce-stable#   Available Packages# Step2: 安装指定版本的Docker-CE: (VERSION例如上面的17.03.0.ce.1-1.el7.centos)# sudo yum  install -y docker-ce-[VERSION]# sudo yum  install -y docker-ce-18.06.3.ce-3.el7echo &#39;docker安装成功...&#39;docker -v</code></pre>]]></content>
      
      
      <categories>
          
          <category> Docker </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Linux </tag>
            
            <tag> Docker </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>样式组件调整</title>
      <link href="/haze/2020/06/13/blog/yang-shi-zu-jian-diao-zheng/"/>
      <url>/haze/2020/06/13/blog/yang-shi-zu-jian-diao-zheng/</url>
      
        <content type="html"><![CDATA[<h1 id="样式组件调整"><a href="#样式组件调整" class="headerlink" title="样式组件调整"></a>样式组件调整</h1><h2 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h2><ul><li><p>简单漂亮，文章内容美观易读</p></li><li><p><a href="https://material.io/" target="_blank" rel="noopener">Material Design</a> 设计</p></li><li><p>响应式设计，博客在桌面端、平板、手机等设备上均能很好的展现</p></li><li><p>首页轮播文章及每天动态切换 <code>Banner</code> 图片</p></li><li><p>瀑布流式的博客文章列表（文章无特色图片时会有 <code>24</code> 张漂亮的图片代替）</p></li><li><p>时间轴式的归档页</p></li><li><p><strong>词云</strong>的标签页和<strong>雷达图</strong>的分类页</p></li><li><p>丰富的关于我页面（包括关于我、文章统计图、我的项目、我的技能、相册等）</p></li><li><p>可自定义的数据的友情链接页面</p></li><li><p>支持文章置顶和文章打赏</p></li><li><p>支持 <code>MathJax</code></p></li><li><p><code>TOC</code> 目录</p></li><li><p>可设置复制文章内容时追加版权信息</p></li><li><p>可设置阅读文章时做密码验证</p></li><li><p><a href="https://gitalk.github.io/" target="_blank" rel="noopener">Gitalk</a>、<a href="https://imsun.github.io/gitment/" target="_blank" rel="noopener">Gitment</a>、<a href="https://valine.js.org/" target="_blank" rel="noopener">Valine</a> 和 <a href="https://disqus.com/" target="_blank" rel="noopener">Disqus</a> 评论模块（推荐使用 <code>Gitalk</code>）</p></li><li><p>集成了<a href="http://busuanzi.ibruce.info/" target="_blank" rel="noopener">不蒜子统计</a>、谷歌分析（<code>Google Analytics</code>）和文章字数统计等功能</p></li><li><p>支持在首页的音乐播放和视频播放功能</p></li><li><p>支持<code>emoji</code>表情，用<code>markdown emoji</code>语法书写直接生成对应的能<strong>跳跃</strong>的表情。</p></li><li><p>支持 <a href="http://www.daovoice.io/" target="_blank" rel="noopener">DaoVoice</a>、<a href="https://www.tidio.com/" target="_blank" rel="noopener">Tidio</a> 在线聊天功能。</p></li><li><p><a href="https://github.com/Five-great" target="_blank" rel="noopener">https://github.com/Five-great</a>)</p></li></ul><h2 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h2><p>当你看到这里的时候，应该已经有一个自己的 <a href="https://hexo.io/zh-cn/" target="_blank" rel="noopener">Hexo</a> 博客了。如果还没有的话，不妨使用 Hexo 和 <a href="https://www.appinn.com/markdown/" target="_blank" rel="noopener">Markdown</a> 来写博客和文章。</p><p>点击 <a href="https://codeload.github.com/blinkfox/hexo-theme-matery/zip/master" target="_blank" rel="noopener">这里</a> 下载 <code>master</code> 分支的最新稳定版的代码，解压缩后，将 <code>hexo-theme-matery</code> 的文件夹复制到你 Hexo 的 <code>themes</code> 文件夹中即可。</p><p>当然你也可以在你的 <code>themes</code> 文件夹下使用 <code>Git clone</code> 命令来下载:</p><pre class=" language-bash"><code class="language-bash"><span class="token function">git</span> clone https://github.com/youknowhaze/hexo-theme-matery.git</code></pre><h2 id="配置"><a href="#配置" class="headerlink" title="配置"></a>配置</h2><h3 id="切换主题"><a href="#切换主题" class="headerlink" title="切换主题"></a>切换主题</h3><p>修改 Hexo 根目录下的 <code>_config.yml</code> 的  <code>theme</code> 的值：<code>theme: hexo-theme-matery</code></p><h4 id="config-yml-文件的其它修改建议"><a href="#config-yml-文件的其它修改建议" class="headerlink" title="_config.yml 文件的其它修改建议:"></a><code>_config.yml</code> 文件的其它修改建议:</h4><ul><li>请修改 <code>_config.yml</code> 的 <code>url</code> 的值为你的网站主 <code>URL</code>（如：<code>http://xxx.github.io</code>）。</li><li>建议修改两个 <code>per_page</code> 的分页条数值为 <code>6</code> 的倍数，如：<code>12</code>、<code>18</code> 等，这样文章列表在各个屏幕下都能较好的显示。</li><li>如果你是中文用户，则建议修改 <code>language</code> 的值为 <code>zh-CN</code>。</li></ul><h3 id="新建分类-categories-页"><a href="#新建分类-categories-页" class="headerlink" title="新建分类 categories 页"></a>新建分类 categories 页</h3><p><code>categories</code> 页是用来展示所有分类的页面，如果在你的博客 <code>source</code> 目录下还没有 <code>categories/index.md</code> 文件，那么你就需要新建一个，命令如下：</p><pre class=" language-bash"><code class="language-bash">hexo new page <span class="token string">"categories"</span></code></pre><p>编辑你刚刚新建的页面文件 <code>/source/categories/index.md</code>，至少需要以下内容：</p><pre class=" language-yaml"><code class="language-yaml"><span class="token punctuation">---</span><span class="token key atrule">title</span><span class="token punctuation">:</span> categories<span class="token key atrule">date</span><span class="token punctuation">:</span> <span class="token datetime number">2018-09-30 17:25:30</span><span class="token key atrule">type</span><span class="token punctuation">:</span> <span class="token string">"categories"</span><span class="token key atrule">layout</span><span class="token punctuation">:</span> <span class="token string">"categories"</span><span class="token punctuation">---</span></code></pre><h3 id="新建标签-tags-页"><a href="#新建标签-tags-页" class="headerlink" title="新建标签 tags 页"></a>新建标签 tags 页</h3><p><code>tags</code> 页是用来展示所有标签的页面，如果在你的博客 <code>source</code> 目录下还没有 <code>tags/index.md</code> 文件，那么你就需要新建一个，命令如下：</p><pre class=" language-bash"><code class="language-bash">hexo new page <span class="token string">"tags"</span></code></pre><p>编辑你刚刚新建的页面文件 <code>/source/tags/index.md</code>，至少需要以下内容：</p><pre class=" language-yaml"><code class="language-yaml"><span class="token punctuation">---</span><span class="token key atrule">title</span><span class="token punctuation">:</span> tags<span class="token key atrule">date</span><span class="token punctuation">:</span> <span class="token datetime number">2018-09-30 18:23:38</span><span class="token key atrule">type</span><span class="token punctuation">:</span> <span class="token string">"tags"</span><span class="token key atrule">layout</span><span class="token punctuation">:</span> <span class="token string">"tags"</span><span class="token punctuation">---</span></code></pre><h3 id="新建关于我-about-页"><a href="#新建关于我-about-页" class="headerlink" title="新建关于我 about 页"></a>新建关于我 about 页</h3><p><code>about</code> 页是用来展示<strong>关于我和我的博客</strong>信息的页面，如果在你的博客 <code>source</code> 目录下还没有 <code>about/index.md</code> 文件，那么你就需要新建一个，命令如下：</p><pre class=" language-bash"><code class="language-bash">hexo new page <span class="token string">"about"</span></code></pre><p>编辑你刚刚新建的页面文件 <code>/source/about/index.md</code>，至少需要以下内容：</p><pre class=" language-yaml"><code class="language-yaml"><span class="token punctuation">---</span><span class="token key atrule">title</span><span class="token punctuation">:</span> about<span class="token key atrule">date</span><span class="token punctuation">:</span> <span class="token datetime number">2018-09-30 17:25:30</span><span class="token key atrule">type</span><span class="token punctuation">:</span> <span class="token string">"about"</span><span class="token key atrule">layout</span><span class="token punctuation">:</span> <span class="token string">"about"</span><span class="token punctuation">---</span></code></pre><h3 id="新建留言板-contact-页（可选的）"><a href="#新建留言板-contact-页（可选的）" class="headerlink" title="新建留言板 contact 页（可选的）"></a>新建留言板 contact 页（可选的）</h3><p><code>contact</code> 页是用来展示<strong>留言板</strong>信息的页面，如果在你的博客 <code>source</code> 目录下还没有 <code>contact/index.md</code> 文件，那么你就需要新建一个，命令如下：</p><pre class=" language-bash"><code class="language-bash">hexo new page <span class="token string">"contact"</span></code></pre><p>编辑你刚刚新建的页面文件 <code>/source/contact/index.md</code>，至少需要以下内容：</p><pre class=" language-yaml"><code class="language-yaml"><span class="token punctuation">---</span><span class="token key atrule">title</span><span class="token punctuation">:</span> contact<span class="token key atrule">date</span><span class="token punctuation">:</span> <span class="token datetime number">2018-09-30 17:25:30</span><span class="token key atrule">type</span><span class="token punctuation">:</span> <span class="token string">"contact"</span><span class="token key atrule">layout</span><span class="token punctuation">:</span> <span class="token string">"contact"</span><span class="token punctuation">---</span></code></pre><blockquote><p><strong>注</strong>：本留言板功能依赖于第三方评论系统，请<strong>激活</strong>你的评论系统才有效果。并且在主题的 <code>_config.yml</code> 文件中，第 <code>19</code> 至 <code>21</code> 行的“<strong>菜单</strong>”配置，取消关于留言板的注释即可。</p></blockquote><h3 id="新建友情链接-friends-页（可选的）"><a href="#新建友情链接-friends-页（可选的）" class="headerlink" title="新建友情链接 friends 页（可选的）"></a>新建友情链接 friends 页（可选的）</h3><p><code>friends</code> 页是用来展示<strong>友情链接</strong>信息的页面，如果在你的博客 <code>source</code> 目录下还没有 <code>friends/index.md</code> 文件，那么你就需要新建一个，命令如下：</p><pre class=" language-bash"><code class="language-bash">hexo new page <span class="token string">"friends"</span></code></pre><p>编辑你刚刚新建的页面文件 <code>/source/friends/index.md</code>，至少需要以下内容：</p><pre class=" language-yaml"><code class="language-yaml"><span class="token punctuation">---</span><span class="token key atrule">title</span><span class="token punctuation">:</span> friends<span class="token key atrule">date</span><span class="token punctuation">:</span> <span class="token datetime number">2018-12-12 21:25:30</span><span class="token key atrule">type</span><span class="token punctuation">:</span> <span class="token string">"friends"</span><span class="token key atrule">layout</span><span class="token punctuation">:</span> <span class="token string">"friends"</span><span class="token punctuation">---</span></code></pre><p>同时，在你的博客 <code>source</code> 目录下新建 <code>_data</code> 目录，在 <code>_data</code> 目录中新建 <code>friends.json</code> 文件，文件内容如下所示：</p><pre class=" language-json"><code class="language-json"><span class="token punctuation">[</span><span class="token punctuation">{</span>    <span class="token property">"avatar"</span><span class="token operator">:</span> <span class="token string">"http://image.luokangyuan.com/1_qq_27922023.jpg"</span><span class="token punctuation">,</span>    <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"码酱"</span><span class="token punctuation">,</span>    <span class="token property">"introduction"</span><span class="token operator">:</span> <span class="token string">"我不是大佬，只是在追寻大佬的脚步"</span><span class="token punctuation">,</span>    <span class="token property">"url"</span><span class="token operator">:</span> <span class="token string">"http://luokangyuan.com/"</span><span class="token punctuation">,</span>    <span class="token property">"title"</span><span class="token operator">:</span> <span class="token string">"前去学习"</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>    <span class="token property">"avatar"</span><span class="token operator">:</span> <span class="token string">"http://image.luokangyuan.com/4027734.jpeg"</span><span class="token punctuation">,</span>    <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"闪烁之狐"</span><span class="token punctuation">,</span>    <span class="token property">"introduction"</span><span class="token operator">:</span> <span class="token string">"编程界大佬，技术牛，人还特别好，不懂的都可以请教大佬"</span><span class="token punctuation">,</span>    <span class="token property">"url"</span><span class="token operator">:</span> <span class="token string">"https://blinkfox.github.io/"</span><span class="token punctuation">,</span>    <span class="token property">"title"</span><span class="token operator">:</span> <span class="token string">"前去学习"</span><span class="token punctuation">}</span><span class="token punctuation">,</span> <span class="token punctuation">{</span>    <span class="token property">"avatar"</span><span class="token operator">:</span> <span class="token string">"http://image.luokangyuan.com/avatar.jpg"</span><span class="token punctuation">,</span>    <span class="token property">"name"</span><span class="token operator">:</span> <span class="token string">"ja_rome"</span><span class="token punctuation">,</span>    <span class="token property">"introduction"</span><span class="token operator">:</span> <span class="token string">"平凡的脚步也可以走出伟大的行程"</span><span class="token punctuation">,</span>    <span class="token property">"url"</span><span class="token operator">:</span> <span class="token string">"https://me.csdn.net/jlh912008548"</span><span class="token punctuation">,</span>    <span class="token property">"title"</span><span class="token operator">:</span> <span class="token string">"前去学习"</span><span class="token punctuation">}</span><span class="token punctuation">]</span></code></pre><h3 id="菜单导航配置"><a href="#菜单导航配置" class="headerlink" title="菜单导航配置"></a>菜单导航配置</h3><h4 id="配置基本菜单导航的名称、路径url和图标icon"><a href="#配置基本菜单导航的名称、路径url和图标icon" class="headerlink" title="配置基本菜单导航的名称、路径url和图标icon."></a>配置基本菜单导航的名称、路径url和图标icon.</h4><p>1.菜单导航名称可以是中文也可以是英文(如：<code>Index</code>或<code>主页</code>)<br>2.图标icon 可以在<a href="https://fontawesome.com/icons" target="_blank" rel="noopener">Font Awesome</a> 中查找</p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">menu</span><span class="token punctuation">:</span>  <span class="token key atrule">Index</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>home  <span class="token key atrule">Tags</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /tags    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>tags  <span class="token key atrule">Categories</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /categories    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>bookmark  <span class="token key atrule">Archives</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /archives    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>archive  <span class="token key atrule">About</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /about    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>user<span class="token punctuation">-</span>circle  <span class="token key atrule">Friends</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /friends    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>address<span class="token punctuation">-</span>book</code></pre><h4 id="二级菜单配置方法"><a href="#二级菜单配置方法" class="headerlink" title="二级菜单配置方法"></a>二级菜单配置方法</h4><p>如果你需要二级菜单则可以在原基本菜单导航的基础上如下操作<br>1.在需要添加二级菜单的一级菜单下添加<code>children</code>关键字(如:<code>About</code>菜单下添加<code>children</code>)<br>2.在<code>children</code>下创建二级菜单的 名称name,路径url和图标icon.<br>3.注意每个二级菜单模块前要加 <code>-</code>.<br>4.注意缩进格式</p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">menu</span><span class="token punctuation">:</span>  <span class="token key atrule">Index</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>home  <span class="token key atrule">Tags</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /tags    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>tags  <span class="token key atrule">Categories</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /categories    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>bookmark  <span class="token key atrule">Archives</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /archives    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>archive  <span class="token key atrule">About</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /about    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>user<span class="token punctuation">-</span>circle<span class="token punctuation">-</span>o  <span class="token key atrule">Friends</span><span class="token punctuation">:</span>    <span class="token key atrule">url</span><span class="token punctuation">:</span> /friends    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>address<span class="token punctuation">-</span>book  <span class="token key atrule">Medias</span><span class="token punctuation">:</span>    <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>list    <span class="token key atrule">children</span><span class="token punctuation">:</span>      <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> Musics        <span class="token key atrule">url</span><span class="token punctuation">:</span> /musics        <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>music      <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> Movies        <span class="token key atrule">url</span><span class="token punctuation">:</span> /movies        <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>film      <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> Books        <span class="token key atrule">url</span><span class="token punctuation">:</span> /books        <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>book      <span class="token punctuation">-</span> <span class="token key atrule">name</span><span class="token punctuation">:</span> Galleries        <span class="token key atrule">url</span><span class="token punctuation">:</span> /galleries        <span class="token key atrule">icon</span><span class="token punctuation">:</span> fas fa<span class="token punctuation">-</span>image</code></pre><p>执行 <code>hexo clean &amp;&amp; hexo g</code> 重新生成博客文件，然后就可以在文章中对应位置看到你用<code>emoji</code>语法写的表情了。</p><h3 id="代码高亮"><a href="#代码高亮" class="headerlink" title="代码高亮"></a>代码高亮</h3><p>由于 Hexo 自带的代码高亮主题显示不好看，所以主题中使用到了 <a href="https://github.com/ele828/hexo-prism-plugin" target="_blank" rel="noopener">hexo-prism-plugin</a> 的 Hexo 插件来做代码高亮，安装命令如下：</p><pre class=" language-bash"><code class="language-bash"><span class="token function">npm</span> i -S hexo-prism-plugin</code></pre><p>然后，修改 Hexo 根目录下 <code>_config.yml</code> 文件中 <code>highlight.enable</code> 的值为 <code>false</code>，并新增 <code>prism</code> 插件相关的配置，主要配置如下：</p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">highlight</span><span class="token punctuation">:</span>  <span class="token key atrule">enable</span><span class="token punctuation">:</span> <span class="token boolean important">false</span><span class="token key atrule">prism_plugin</span><span class="token punctuation">:</span>  <span class="token key atrule">mode</span><span class="token punctuation">:</span> <span class="token string">'preprocess'</span>    <span class="token comment" spellcheck="true"># realtime/preprocess</span>  <span class="token key atrule">theme</span><span class="token punctuation">:</span> <span class="token string">'tomorrow'</span>  <span class="token key atrule">line_number</span><span class="token punctuation">:</span> <span class="token boolean important">false    </span><span class="token comment" spellcheck="true"># default false</span>  custom_css<span class="token punctuation">:</span></code></pre><h3 id="搜索"><a href="#搜索" class="headerlink" title="搜索"></a>搜索</h3><p>本主题中还使用到了 <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener">hexo-generator-search</a> 的 Hexo 插件来做内容搜索，安装命令如下：</p><pre class=" language-bash"><code class="language-bash"><span class="token function">npm</span> <span class="token function">install</span> hexo-generator-search --save</code></pre><p>在 Hexo 根目录下的 <code>_config.yml</code> 文件中，新增以下的配置项：</p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">search</span><span class="token punctuation">:</span>  <span class="token key atrule">path</span><span class="token punctuation">:</span> search.xml  <span class="token key atrule">field</span><span class="token punctuation">:</span> post</code></pre><h3 id="中文链接转拼音（建议安装）"><a href="#中文链接转拼音（建议安装）" class="headerlink" title="中文链接转拼音（建议安装）"></a>中文链接转拼音（建议安装）</h3><p>如果你的文章名称是中文的，那么 Hexo 默认生成的永久链接也会有中文，这样不利于 <code>SEO</code>，且 <code>gitment</code> 评论对中文链接也不支持。我们可以用 <a href="https://github.com/viko16/hexo-permalink-pinyin" target="_blank" rel="noopener">hexo-permalink-pinyin</a> Hexo 插件使在生成文章时生成中文拼音的永久链接。</p><p>安装命令如下：</p><pre class=" language-bash"><code class="language-bash"><span class="token function">npm</span> i hexo-permalink-pinyin --save</code></pre><p>在 Hexo 根目录下的 <code>_config.yml</code> 文件中，新增以下的配置项：</p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">permalink_pinyin</span><span class="token punctuation">:</span>  <span class="token key atrule">enable</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>  <span class="token key atrule">separator</span><span class="token punctuation">:</span> <span class="token string">'-'</span> <span class="token comment" spellcheck="true"># default: '-'</span></code></pre><blockquote><p><strong>注</strong>：除了此插件外，<a href="https://github.com/rozbo/hexo-abbrlink" target="_blank" rel="noopener">hexo-abbrlink</a> 插件也可以生成非中文的链接。</p></blockquote><h3 id="文章字数统计插件（建议安装）"><a href="#文章字数统计插件（建议安装）" class="headerlink" title="文章字数统计插件（建议安装）"></a>文章字数统计插件（建议安装）</h3><p>如果你想要在文章中显示文章字数、阅读时长信息，可以安装 <a href="https://github.com/willin/hexo-wordcount" target="_blank" rel="noopener">hexo-wordcount</a>插件。</p><p>安装命令如下：</p><pre class=" language-bash"><code class="language-bash"><span class="token function">npm</span> i --save hexo-wordcount</code></pre><p>然后只需在本主题下的 <code>_config.yml</code> 文件中，将各个文章字数相关的配置激活即可：</p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">postInfo</span><span class="token punctuation">:</span>  <span class="token key atrule">date</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>  <span class="token key atrule">update</span><span class="token punctuation">:</span> <span class="token boolean important">false</span>  <span class="token key atrule">wordCount</span><span class="token punctuation">:</span> <span class="token boolean important">false </span><span class="token comment" spellcheck="true"># 设置文章字数统计为 true.</span>  <span class="token key atrule">totalCount</span><span class="token punctuation">:</span> <span class="token boolean important">false </span><span class="token comment" spellcheck="true"># 设置站点文章总字数统计为 true.</span>  <span class="token key atrule">min2read</span><span class="token punctuation">:</span> <span class="token boolean important">false </span><span class="token comment" spellcheck="true"># 阅读时长.</span>  <span class="token key atrule">readCount</span><span class="token punctuation">:</span> <span class="token boolean important">false </span><span class="token comment" spellcheck="true"># 阅读次数.</span></code></pre><h3 id="添加emoji表情支持（可选的）"><a href="#添加emoji表情支持（可选的）" class="headerlink" title="添加emoji表情支持（可选的）"></a>添加emoji表情支持（可选的）</h3><p>本主题新增了对<code>emoji</code>表情的支持，使用到了 <a href="https://npm.taobao.org/package/hexo-filter-github-emojis" target="_blank" rel="noopener">hexo-filter-github-emojis</a> 的 Hexo 插件来支持 <code>emoji</code>表情的生成，把对应的<code>markdown emoji</code>语法（<code>::</code>,例如：<code>:smile:</code>）转变成会跳跃的<code>emoji</code>表情，安装命令如下：</p><pre class=" language-bash"><code class="language-bash"><span class="token function">npm</span> <span class="token function">install</span> hexo-filter-github-emojis --save</code></pre><p>在 Hexo 根目录下的 <code>_config.yml</code> 文件中，新增以下的配置项：</p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">githubEmojis</span><span class="token punctuation">:</span>  <span class="token key atrule">enable</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>  <span class="token key atrule">className</span><span class="token punctuation">:</span> github<span class="token punctuation">-</span>emoji  <span class="token key atrule">inject</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>  <span class="token key atrule">styles</span><span class="token punctuation">:</span>  customEmojis<span class="token punctuation">:</span></code></pre><h3 id="添加-RSS-订阅支持（可选的）"><a href="#添加-RSS-订阅支持（可选的）" class="headerlink" title="添加 RSS 订阅支持（可选的）"></a>添加 RSS 订阅支持（可选的）</h3><p>本主题中还使用到了 <a href="https://github.com/hexojs/hexo-generator-feed" target="_blank" rel="noopener">hexo-generator-feed</a> 的 Hexo 插件来做 <code>RSS</code>，安装命令如下：</p><pre class=" language-bash"><code class="language-bash"><span class="token function">npm</span> <span class="token function">install</span> hexo-generator-feed --save</code></pre><p>在 Hexo 根目录下的 <code>_config.yml</code> 文件中，新增以下的配置项：</p><pre class=" language-yaml"><code class="language-yaml"><span class="token key atrule">feed</span><span class="token punctuation">:</span>  <span class="token key atrule">type</span><span class="token punctuation">:</span> atom  <span class="token key atrule">path</span><span class="token punctuation">:</span> atom.xml  <span class="token key atrule">limit</span><span class="token punctuation">:</span> <span class="token number">20</span>  <span class="token key atrule">hub</span><span class="token punctuation">:</span>  <span class="token key atrule">content</span><span class="token punctuation">:</span>  <span class="token key atrule">content_limit</span><span class="token punctuation">:</span> <span class="token number">140</span>  <span class="token key atrule">content_limit_delim</span><span class="token punctuation">:</span> <span class="token string">' '</span>  <span class="token key atrule">order_by</span><span class="token punctuation">:</span> <span class="token punctuation">-</span>date</code></pre><p>执行 <code>hexo clean &amp;&amp; hexo g</code> 重新生成博客文件，然后在 <code>public</code> 文件夹中即可看到 <code>atom.xml</code> 文件，说明你已经安装成功了。</p><h3 id="添加-DaoVoice-在线聊天功能（可选的）"><a href="#添加-DaoVoice-在线聊天功能（可选的）" class="headerlink" title="添加 DaoVoice 在线聊天功能（可选的）"></a>添加 <a href="http://www.daovoice.io/" target="_blank" rel="noopener">DaoVoice</a> 在线聊天功能（可选的）</h3><p>前往 <a href="http://www.daovoice.io/" target="_blank" rel="noopener">DaoVoice</a> 官网注册并且获取 <code>app_id</code>，并将 <code>app_id</code> 填入主题的 <code>_config.yml</code> 文件中。</p><h3 id="添加-Tidio-在线聊天功能（可选的）"><a href="#添加-Tidio-在线聊天功能（可选的）" class="headerlink" title="添加 Tidio 在线聊天功能（可选的）"></a>添加 <a href="https://www.tidio.com/" target="_blank" rel="noopener">Tidio</a> 在线聊天功能（可选的）</h3><p>前往 <a href="https://www.tidio.com/" target="_blank" rel="noopener">Tidio</a> 官网注册并且获取 <code>Public Key</code>，并将 <code>Public Key</code> 填入主题的 <code>_config.yml</code> 文件中。</p><h3 id="修改页脚"><a href="#修改页脚" class="headerlink" title="修改页脚"></a>修改页脚</h3><p>页脚信息可能需要做定制化修改，而且它不便于做成配置信息，所以可能需要你自己去再修改和加工。修改的地方在主题文件的 <code>/layout/_partial/footer.ejs</code> 文件中，包括站点、使用的主题、访问量等。</p><h3 id="修改社交链接"><a href="#修改社交链接" class="headerlink" title="修改社交链接"></a>修改社交链接</h3><p>在主题的 <code>_config.yml</code> 文件中，默认支持 <code>QQ</code>、<code>GitHub</code> 和邮箱等的配置，你可以在主题文件的 <code>/layout/_partial/social-link.ejs</code> 文件中，新增、修改你需要的社交链接地址，增加链接可参考如下代码：</p><pre class=" language-html"><code class="language-html"><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>%</span> <span class="token attr-name">if</span> <span class="token attr-name">(theme.socialLink.github)</span> <span class="token attr-name">{</span> <span class="token attr-name">%</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>a</span> <span class="token attr-name">href</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>&lt;%<span class="token punctuation">=</span> theme.socialLink.github %<span class="token punctuation">></span><span class="token punctuation">"</span></span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>tooltipped<span class="token punctuation">"</span></span> <span class="token attr-name">target</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>_blank<span class="token punctuation">"</span></span> <span class="token attr-name">data-tooltip</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>访问我的GitHub<span class="token punctuation">"</span></span> <span class="token attr-name">data-position</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>top<span class="token punctuation">"</span></span> <span class="token attr-name">data-delay</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>50<span class="token punctuation">"</span></span><span class="token punctuation">></span></span>        <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>i</span> <span class="token attr-name">class</span><span class="token attr-value"><span class="token punctuation">=</span><span class="token punctuation">"</span>fab fa-github<span class="token punctuation">"</span></span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>i</span><span class="token punctuation">></span></span>    <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>a</span><span class="token punctuation">></span></span><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>%</span> <span class="token attr-name">}</span> <span class="token attr-name">%</span><span class="token punctuation">></span></span></code></pre><p>其中，社交图标（如：<code>fa-github</code>）你可以在 <a href="https://fontawesome.com/icons" target="_blank" rel="noopener">Font Awesome</a> 中搜索找到。以下是常用社交图标的标识，供你参考：</p><ul><li>Facebook: <code>fab fa-facebook</code></li><li>Twitter: <code>fab fa-twitter</code></li><li>Google-plus: <code>fab fa-google-plus</code></li><li>Linkedin: <code>fab fa-linkedin</code></li><li>Tumblr: <code>fab fa-tumblr</code></li><li>Medium: <code>fab fa-medium</code></li><li>Slack: <code>fab fa-slack</code></li><li>Sina Weibo: <code>fab fa-weibo</code></li><li>Wechat: <code>fab fa-weixin</code></li><li>QQ: <code>fab fa-qq</code></li><li>Zhihu: <code>fab fa-zhihu</code></li></ul><blockquote><p><strong>注意</strong>: 本主题中使用的 <code>Font Awesome</code> 版本为 <code>5.11.0</code>。</p></blockquote><h3 id="修改打赏的二维码图片"><a href="#修改打赏的二维码图片" class="headerlink" title="修改打赏的二维码图片"></a>修改打赏的二维码图片</h3><p>在主题文件的 <code>source/medias/reward</code> 文件中，你可以替换成你的的微信和支付宝的打赏二维码图片。</p><h3 id="配置音乐播放器（可选的）"><a href="#配置音乐播放器（可选的）" class="headerlink" title="配置音乐播放器（可选的）"></a>配置音乐播放器（可选的）</h3><p>要支持音乐播放，在主题的 <code>_config.yml</code> 配置文件中激活music配置即可：</p><pre class=" language-yaml"><code class="language-yaml"><span class="token comment" spellcheck="true"># 是否在首页显示音乐</span><span class="token key atrule">music</span><span class="token punctuation">:</span>  <span class="token key atrule">enable</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>  <span class="token key atrule">title</span><span class="token punctuation">:</span>             <span class="token comment" spellcheck="true">#非吸底模式有效</span>    <span class="token key atrule">enable</span><span class="token punctuation">:</span> <span class="token boolean important">true</span>    <span class="token key atrule">show</span><span class="token punctuation">:</span> 听听音乐  <span class="token key atrule">server</span><span class="token punctuation">:</span> netease   <span class="token comment" spellcheck="true">#require music platform: netease, tencent, kugou, xiami, baidu</span>  <span class="token key atrule">type</span><span class="token punctuation">:</span> playlist    <span class="token comment" spellcheck="true">#require song, playlist, album, search, artist</span>  <span class="token key atrule">id</span><span class="token punctuation">:</span> <span class="token number">503838841     </span><span class="token comment" spellcheck="true">#require song id / playlist id / album id / search keyword</span>  <span class="token key atrule">fixed</span><span class="token punctuation">:</span> <span class="token boolean important">false      </span><span class="token comment" spellcheck="true"># 开启吸底模式</span>  <span class="token key atrule">autoplay</span><span class="token punctuation">:</span> <span class="token boolean important">false   </span><span class="token comment" spellcheck="true"># 是否自动播放</span>  <span class="token key atrule">theme</span><span class="token punctuation">:</span> '<span class="token comment" spellcheck="true">#42b983'</span>  <span class="token key atrule">loop</span><span class="token punctuation">:</span> <span class="token string">'all'</span>       <span class="token comment" spellcheck="true"># 音频循环播放, 可选值: 'all', 'one', 'none'</span>  <span class="token key atrule">order</span><span class="token punctuation">:</span> <span class="token string">'random'</span>   <span class="token comment" spellcheck="true"># 音频循环顺序, 可选值: 'list', 'random'</span>  <span class="token key atrule">preload</span><span class="token punctuation">:</span> <span class="token string">'auto'</span>   <span class="token comment" spellcheck="true"># 预加载，可选值: 'none', 'metadata', 'auto'</span>  <span class="token key atrule">volume</span><span class="token punctuation">:</span> <span class="token number">0.7       </span><span class="token comment" spellcheck="true"># 默认音量，请注意播放器会记忆用户设置，用户手动设置音量后默认音量即失效</span>  <span class="token key atrule">listFolded</span><span class="token punctuation">:</span> <span class="token boolean important">true  </span><span class="token comment" spellcheck="true"># 列表默认折叠</span></code></pre><blockquote><p><code>server</code>可选<code>netease</code>（网易云音乐），<code>tencent</code>（QQ音乐），<code>kugou</code>（酷狗音乐），<code>xiami</code>（虾米音乐），</p><p><code>baidu</code>（百度音乐）。</p><p><code>type</code>可选<code>song</code>（歌曲），<code>playlist</code>（歌单），<code>album</code>（专辑），<code>search</code>（搜索关键字），<code>artist</code>（歌手）</p><p><code>id</code>获取示例: 浏览器打开网易云音乐，点击我喜欢的音乐歌单，地址栏有一串数字，<code>playlist</code>的<code>id</code>即为这串数字。</p></blockquote><h2 id="文章-Front-matter-介绍"><a href="#文章-Front-matter-介绍" class="headerlink" title="文章 Front-matter 介绍"></a>文章 Front-matter 介绍</h2><h3 id="Front-matter-选项详解"><a href="#Front-matter-选项详解" class="headerlink" title="Front-matter 选项详解"></a>Front-matter 选项详解</h3><p><code>Front-matter</code> 选项中的所有内容均为<strong>非必填</strong>的。但我仍然建议至少填写 <code>title</code> 和 <code>date</code> 的值。</p><table><thead><tr><th>配置选项</th><th>默认值</th><th>描述</th></tr></thead><tbody><tr><td>title</td><td><code>Markdown</code> 的文件标题</td><td>文章标题，强烈建议填写此选项</td></tr><tr><td>date</td><td>文件创建时的日期时间</td><td>发布时间，强烈建议填写此选项，且最好保证全局唯一</td></tr><tr><td>author</td><td>根 <code>_config.yml</code> 中的 <code>author</code></td><td>文章作者</td></tr><tr><td>img</td><td><code>featureImages</code> 中的某个值</td><td>文章特征图，推荐使用图床(腾讯云、七牛云、又拍云等)来做图片的路径.如: <code>http://xxx.com/xxx.jpg</code></td></tr><tr><td>top</td><td><code>true</code></td><td>推荐文章（文章是否置顶），如果 <code>top</code> 值为 <code>true</code>，则会作为首页推荐文章</td></tr><tr><td>cover</td><td><code>false</code></td><td><code>v1.0.2</code>版本新增，表示该文章是否需要加入到首页轮播封面中</td></tr><tr><td>coverImg</td><td>无</td><td><code>v1.0.2</code>版本新增，表示该文章在首页轮播封面需要显示的图片路径，如果没有，则默认使用文章的特色图片</td></tr><tr><td>password</td><td>无</td><td>文章阅读密码，如果要对文章设置阅读验证密码的话，就可以设置 <code>password</code> 的值，该值必须是用 <code>SHA256</code> 加密后的密码，防止被他人识破。前提是在主题的 <code>config.yml</code> 中激活了 <code>verifyPassword</code> 选项</td></tr><tr><td>toc</td><td><code>true</code></td><td>是否开启 TOC，可以针对某篇文章单独关闭 TOC 的功能。前提是在主题的 <code>config.yml</code> 中激活了 <code>toc</code> 选项</td></tr><tr><td>mathjax</td><td><code>false</code></td><td>是否开启数学公式支持 ，本文章是否开启 <code>mathjax</code>，且需要在主题的 <code>_config.yml</code> 文件中也需要开启才行</td></tr><tr><td>summary</td><td>无</td><td>文章摘要，自定义的文章摘要内容，如果这个属性有值，文章卡片摘要就显示这段文字，否则程序会自动截取文章的部分内容作为摘要</td></tr><tr><td>categories</td><td>无</td><td>文章分类，本主题的分类表示宏观上大的分类，只建议一篇文章一个分类</td></tr><tr><td>tags</td><td>无</td><td>文章标签，一篇文章可以多个标签</td></tr><tr><td>keywords</td><td>文章标题</td><td>文章关键字，SEO 时需要</td></tr><tr><td>reprintPolicy</td><td>cc_by</td><td>文章转载规则， 可以是 cc_by, cc_by_nd, cc_by_sa, cc_by_nc, cc_by_nc_nd, cc_by_nc_sa, cc0, noreprint 或 pay 中的一个</td></tr></tbody></table><blockquote><p><strong>注意</strong>:</p><ol><li>如果 <code>img</code> 属性不填写的话，文章特色图会根据文章标题的 <code>hashcode</code> 的值取余，然后选取主题中对应的特色图片，从而达到让所有文章都的特色图<strong>各有特色</strong>。</li><li><code>date</code> 的值尽量保证每篇文章是唯一的，因为本主题中 <code>Gitalk</code> 和 <code>Gitment</code> 识别 <code>id</code> 是通过 <code>date</code> 的值来作为唯一标识的。</li><li>如果要对文章设置阅读验证密码的功能，不仅要在 Front-matter 中设置采用了 SHA256 加密的 password 的值，还需要在主题的 <code>_config.yml</code> 中激活了配置。有些在线的 SHA256 加密的地址，可供你使用：<a href="http://tool.oschina.net/encrypt?type=2" target="_blank" rel="noopener">开源中国在线工具</a>、<a href="http://encode.chahuo.com/" target="_blank" rel="noopener">chahuo</a>、<a href="http://tool.chinaz.com/tools/hash.aspx" target="_blank" rel="noopener">站长工具</a>。</li><li>您可以在文章md文件的 front-matter 中指定 reprintPolicy 来给单个文章配置转载规则</li></ol></blockquote><p>以下为文章的 <code>Front-matter</code> 示例。</p><h3 id="最简示例"><a href="#最简示例" class="headerlink" title="最简示例"></a>最简示例</h3><pre class=" language-yaml"><code class="language-yaml"><span class="token punctuation">---</span><span class="token key atrule">title</span><span class="token punctuation">:</span> typora<span class="token punctuation">-</span>vue<span class="token punctuation">-</span>theme主题介绍<span class="token key atrule">date</span><span class="token punctuation">:</span> <span class="token datetime number">2018-09-07 09:25:00</span><span class="token punctuation">---</span></code></pre><h3 id="最全示例"><a href="#最全示例" class="headerlink" title="最全示例"></a>最全示例</h3><pre class=" language-yaml"><code class="language-yaml"><span class="token punctuation">---</span><span class="token key atrule">title</span><span class="token punctuation">:</span> typora<span class="token punctuation">-</span>vue<span class="token punctuation">-</span>theme主题介绍<span class="token key atrule">date</span><span class="token punctuation">:</span> <span class="token datetime number">2018-09-07 09:25:00</span><span class="token key atrule">author</span><span class="token punctuation">:</span> 赵奇<span class="token key atrule">img</span><span class="token punctuation">:</span> /source/images/xxx.jpg<span class="token key atrule">top</span><span class="token punctuation">:</span> <span class="token boolean important">true</span><span class="token key atrule">cover</span><span class="token punctuation">:</span> <span class="token boolean important">true</span><span class="token key atrule">coverImg</span><span class="token punctuation">:</span> /images/1.jpg<span class="token key atrule">password</span><span class="token punctuation">:</span> 8d969eef6ecad3c29a3a629280e686cf0c3f5d5a86aff3ca12020c923adc6c92<span class="token key atrule">toc</span><span class="token punctuation">:</span> <span class="token boolean important">false</span><span class="token key atrule">mathjax</span><span class="token punctuation">:</span> <span class="token boolean important">false</span><span class="token key atrule">summary</span><span class="token punctuation">:</span> 这是你自定义的文章摘要内容，如果这个属性有值，文章卡片摘要就显示这段文字，否则程序会自动截取文章的部分内容作为摘要<span class="token key atrule">categories</span><span class="token punctuation">:</span> Markdown<span class="token key atrule">tags</span><span class="token punctuation">:</span>  <span class="token punctuation">-</span> Typora  <span class="token punctuation">-</span> Markdown<span class="token punctuation">---</span></code></pre><h2 id="效果截图"><a href="#效果截图" class="headerlink" title="效果截图"></a>效果截图</h2><p><img src="http://static.blinkfox.com/matery-20181202-1.png" alt="首页"></p><p><img src="http://static.blinkfox.com/matery-20181202-2.png" alt="首页推荐文章"></p><p><img src="http://static.blinkfox.com/matery-20181202-3.png" alt="首页文章列表"></p><p><img src="http://static.blinkfox.com/matery-20181202-7.png" alt="首页文章列表"></p><p><img src="http://static.blinkfox.com/matery-20181202-8.png" alt="首页文章列表"></p><h2 id="自定制修改"><a href="#自定制修改" class="headerlink" title="自定制修改"></a>自定制修改</h2><p>在本主题的 <code>_config.yml</code> 中可以修改部分自定义信息，有以下几个部分：</p><ul><li>菜单</li><li>我的梦想</li><li>首页的音乐播放器和视频播放器配置</li><li>是否显示推荐文章名称和按钮配置</li><li><code>favicon</code> 和 <code>Logo</code></li><li>个人信息</li><li>TOC 目录</li><li>文章打赏信息</li><li>复制文章内容时追加版权信息</li><li>MathJax</li><li>文章字数统计、阅读时长</li><li>点击页面的’爱心’效果</li><li>我的项目</li><li>我的技能</li><li>我的相册</li><li><code>Gitalk</code>、<code>Gitment</code>、<code>Valine</code> 和 <code>disqus</code> 评论配置</li><li><a href="http://busuanzi.ibruce.info/" target="_blank" rel="noopener">不蒜子统计</a>和谷歌分析（<code>Google Analytics</code>）</li><li>默认特色图的集合。当文章没有设置特色图时，本主题会根据文章标题的 <code>hashcode</code> 值取余，来选择展示对应的特色图</li></ul><p><strong>我认为个人博客应该都有自己的风格和特色</strong>。如果本主题中的诸多功能和主题色彩你不满意，可以在主题中自定义修改，很多更自由的功能和细节点的修改难以在主题的 <code>_config.yml</code> 中完成，需要修改源代码才来完成。以下列出了可能对你有用的地方：</p><h3 id="修改主题颜色"><a href="#修改主题颜色" class="headerlink" title="修改主题颜色"></a>修改主题颜色</h3><p>在主题文件的 <code>/source/css/matery.css</code> 文件中，搜索 <code>.bg-color</code> 来修改背景颜色：</p><pre class=" language-css"><code class="language-css"><span class="token comment" spellcheck="true">/* 整体背景颜色，包括导航、移动端的导航、页尾、标签页等的背景颜色. */</span><span class="token selector"><span class="token class">.bg-color</span> </span><span class="token punctuation">{</span>    <span class="token property">background-image</span><span class="token punctuation">:</span> <span class="token function">linear-gradient</span><span class="token punctuation">(</span>to right, <span class="token hexcode">#4cbf30</span> <span class="token number">0%</span>, <span class="token hexcode">#0f9d58</span> <span class="token number">100%</span><span class="token punctuation">)</span><span class="token punctuation">;</span><span class="token punctuation">}</span><span class="token atrule"><span class="token rule">@-webkit-keyframes</span> rainbow</span> <span class="token punctuation">{</span>   <span class="token comment" spellcheck="true">/* 动态切换背景颜色. */</span><span class="token punctuation">}</span><span class="token atrule"><span class="token rule">@keyframes</span> rainbow</span> <span class="token punctuation">{</span>    <span class="token comment" spellcheck="true">/* 动态切换背景颜色. */</span><span class="token punctuation">}</span></code></pre><h3 id="修改-banner-图和文章特色图"><a href="#修改-banner-图和文章特色图" class="headerlink" title="修改 banner 图和文章特色图"></a>修改 banner 图和文章特色图</h3><p>你可以直接在 <code>/source/medias/banner</code> 文件夹中更换你喜欢的 <code>banner</code> 图片，主题代码中是每天动态切换一张，只需 <code>7</code> 张即可。如果你会 <code>JavaScript</code> 代码，可以修改成你自己喜欢切换逻辑，如：随机切换等，<code>banner</code> 切换的代码位置在 <code>/layout/_partial/bg-cover-content.ejs</code> 文件的 <code>&lt;script&gt;&lt;/script&gt;</code> 代码中：</p><pre class=" language-javascript"><code class="language-javascript"><span class="token function">$</span><span class="token punctuation">(</span><span class="token string">'.bg-cover'</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">css</span><span class="token punctuation">(</span><span class="token string">'background-image'</span><span class="token punctuation">,</span> <span class="token string">'url(/medias/banner/'</span> <span class="token operator">+</span> <span class="token keyword">new</span> <span class="token class-name">Date</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">getDay</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'.jpg)'</span><span class="token punctuation">)</span><span class="token punctuation">;</span></code></pre><p>在 <code>/source/medias/featureimages</code> 文件夹中默认有 24 张特色图片，你可以再增加或者减少，并需要在 <code>_config.yml</code> 做同步修改。</p>]]></content>
      
      
      <categories>
          
          <category> 博客 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> blog </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hexo+github的静态博客搭建</title>
      <link href="/haze/2020/06/06/blog/bo-ke-da-jian/"/>
      <url>/haze/2020/06/06/blog/bo-ke-da-jian/</url>
      
        <content type="html"><![CDATA[<h2 id="从无到有的github博客搭建"><a href="#从无到有的github博客搭建" class="headerlink" title="从无到有的github博客搭建"></a>从无到有的github博客搭建</h2><h3 id="一、基于Hexo-github的静态博客搭建"><a href="#一、基于Hexo-github的静态博客搭建" class="headerlink" title="一、基于Hexo+github的静态博客搭建"></a>一、基于Hexo+github的静态博客搭建</h3><h4 id="1、环境安装"><a href="#1、环境安装" class="headerlink" title="1、环境安装"></a>1、环境安装</h4><p>  因为我是windows系统，所以下面的操作都是基于windows环境而言的<br>  （1）、<strong>Git Bash安装</strong>。我一直不太喜欢使用小乌龟，于是选择git bash进行安装。安装步骤便不再赘述。  <a href="https://gitforwindows.org/" target="_blank" rel="noopener">下载地址</a></p><p>  （2）、<strong>安装NodeJs</strong>。Hexo是基于nodeJS环境的静态博客，里面的npm工具很有用。同样，安装步骤不再赘述   <a href="https://nodejs.org/en/" target="_blank" rel="noopener">下载地址</a></p><p>  （3）、<strong>安装hexo</strong>。看到这么多需要安装的东西，千万不要慌张，这都是开发的必备环境，是比较简单的一些安装操作。建议全局安装hexo，安装命令如下：</p><pre><code>npm i -g hexo</code></pre><p>  （4）、需要拥有一个github账号，若没有，<a href="https://gitforwindows.org/" target="_blank" rel="noopener">去创建</a></p><h4 id="2、创建博客"><a href="#2、创建博客" class="headerlink" title="2、创建博客"></a>2、创建博客</h4><p>  （1）、在github远程仓库创建一个项目，项目名为username.github.io（比如我的github用户名为youknowhaze，那么我的项目名就是youknowhaze.github.io），github会将该名称的项目发布至远程，进行免费托管。每个github账户仅支持这样一个命名项目的托管。</p><p>  （2）、将项目clone至本地目录，进入项目根目录，执行初始化命令</p><pre><code>hexo init</code></pre><p>  初始化后的项目结构如下：</p><p><img src="/haze/2020/06/06/blog/bo-ke-da-jian/blog_init.png" alt="1"></p><p>  简单解释一下这个结构</p><table><thead><tr><th>模块/文件</th><th>作用</th></tr></thead><tbody><tr><td>node_modules</td><td>是依赖包</td></tr><tr><td>public</td><td>存放的是生成的页面</td></tr><tr><td>scaffolds</td><td>命令生成文章等的模板</td></tr><tr><td>source</td><td>用命令创建的各种文章</td></tr><tr><td>themes</td><td>主题</td></tr><tr><td>_config.yml</td><td>整个博客的配置</td></tr><tr><td>db.json</td><td>source解析所得到的</td></tr><tr><td>package.json</td><td>项目所需模块项目的配置信息</td></tr></tbody></table><p>  （3）、启动项目：</p><pre><code>hexo g    # 构建项目，会在public下生成html页面hexo d    # 启动项目，启动后本地访问http://localhost:4000</code></pre><p>初始的博客页面有点丑，访问页面如下：</p><p><img src="/haze/2020/06/06/blog/bo-ke-da-jian/blogpage_1.png" alt="1"></p><p>  （4）、修改主题<br>  既然默认主题比较丑，那么我们就修改一个自己喜欢的主题，  <a href="https://hexo.io/themes/" target="_blank" rel="noopener">官方主题</a><br>  现在使用的博客模板为：  <a href="https://github.com/youknowhaze/incredible-blog" target="_blank" rel="noopener">hexo-theme-matery</a></p><p>  首先修改_config.yml文件中的theme: landscape改为theme: hexo-theme-matery ，然后需要下载模板文件至themes目录下，可以通过clone的方式，也可以下载压缩包进行解压，如下：</p><p><img src="/haze/2020/06/06/blog/bo-ke-da-jian/blog_themes.png" alt="1"></p><p>  重新启动博客：</p><pre><code>hexo s  # 启动博客## 若启动过程中出现报错，可以先清理缓存再启动hexo clean</code></pre><h4 id="3、博客样式及组件调整"><a href="#3、博客样式及组件调整" class="headerlink" title="3、博客样式及组件调整"></a>3、博客样式及组件调整</h4>]]></content>
      
      
      <categories>
          
          <category> 博客 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> blog </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
